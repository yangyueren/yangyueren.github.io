{"posts":[{"title":"华为MindSpore数据集加载算子开发","content":"MindData 是 MindSpore 的数据处理系统， 为 MindSpore 提供了数据加载和预处理管 道。在训练场景，MindData 负责将训练数据从文件系统加载到训练系统，通过数据处理管道， 进行一系列变换和数据增强，最终组成 Tensor，输入到计算框架进行前向和 反向计算。在推理场景，MindData将推理数据加载到内存，通过预定义的变换后，以 Tensor 形式输入给计算框架进行推理。 MindData支持python层和C++层API定义数据加载和数据处理流水线，MindData会运行Execution Tree，树上的每个节点对应数据处理流水线中的一步具体操作，例如在数据加载后有各种数据增强的Map算子、Repeat算子，本文将介绍最基本的数据集加载算子。 一 个 完 整 的 数 据 处 理 算 子 包 含 四 部 分 ： 算 子 Op 实 现 、 算 子 IR （ Intermediate Representation）层定义、Python 层接口定义和 C++层接口定义。 docker环境配置 docker pull mindspore/mindspore-cpu:devel docker run -it -p 8023:22 -p 10022:10022 --name=&quot;mindspore&quot; -v /home/docker_swap:/docker_swap mindspore/mindspore-cpu /bin/bash 进入docker后，下载mindspore代码，安装ssh和libboost-dev apt udpate apt upgrade apt-get install libboost-dev apt-get install openssh-server //使用vscode连接docker进行开发 cd ~ git clone https://gitee.com/yangyueren/mindspore.git 编译 cd mindspore bash build.sh -e cpu –j24 –t on (wait for a long time) pip install ./mindspore/build/package/mindspore-1.2.0-cp37-cp37m-linux_x86_64.whl 数据集加载算子开发 以places365数据集为例，详述数据集加载算子的开发过程。 完整代码：https://gitee.com/yangyueren/mindspore/tree/op_places365/ 新建分支 git checkout –b places365_dataset 开发places365数据集加载算子需要修改或添加以下文件： # 底层算子op开发，加载数据集的最底层的类 mindspore/ccsrc/minddata/dataset/engine/datasetops/source/CMakeLists.txt mindspore/ccsrc/minddata/dataset/engine/datasetops/source/places365_op.cc mindspore/ccsrc/minddata/dataset/engine/datasetops/source/places365_op.h # 中间node表示层开发（IR层） mindspore/ccsrc/minddata/dataset/engine/ir/datasetops/dataset_node.h mindspore/ccsrc/minddata/dataset/engine/ir/datasetops/source/CMakeLists.txt mindspore/ccsrc/minddata/dataset/engine/ir/datasetops/source/places365_node.cc mindspore/ccsrc/minddata/dataset/engine/ir/datasetops/source/places365_node.h # C++层API mindspore/ccsrc/minddata/dataset/api/datasets.cc mindspore/ccsrc/minddata/dataset/include/datasets.h mindspore/ccsrc/minddata/dataset/include/samplers.h # Python API，绑定到C++开发的算子上 mindspore/ccsrc/minddata/dataset/api/python/bindings/dataset/engine/datasetops/source/bindings.cc mindspore/ccsrc/minddata/dataset/api/python/bindings/dataset/engine/ir/datasetops/source/bindings.cc mindspore/dataset/engine/validators.py mindspore/dataset/engine/datasets.py 底层Op算子开发 这里以places365数据集为例，Places365数据集包含365个场景，train-standard包含180万张图片，train-challenge包含800万张图片，val中包含36500张图片。 Places365数据集提供了两套上述数据集，分别是高分辨率和256*256低分辨率图像。数据集格式如下： places365/ // root directory of places365 |---categories_places365.txt //两列，第一列是类别名，第二列是类别ID |---places365_train-standard.txt //两列，第一列是图片的路径，第二列是类别ID |---places365_train-challenge.txt //两列，第一列是图片的路径，第二列是类别ID |---train_large_places365standard/ //存放train-standard高分辨率图片 |---train_large_places365challenge/ //存放train-challenge高分辨率图片 |---val_large/ //存放val高分辨率图片 |---train_256_places365standard/ //存放train-standard低分辨率图片 |---train_256_places365standard/ //存放train-challenge低分辨率图片 |---val_256/ //存放val低分辨率图片 本算子将读取数据集中的图片和label，将其封装为Tensor返回，列名为image和label。 在加载places365数据集时，需要指定以下参数： @param std::string root - root directory of places365 @param const std::string &amp;usage - Usage of this dataset, can be 'train-standard', 'train-challenge' or 'val'. Read the images in this folder and load this meta information. @param bool small - Use high resolution images or 256*256 resolution images. @param bool decode - Decode images usage 决定了加载哪个数据集 usage 和 small参数共同决定了加载哪个文件夹、哪个分辨率大小的数据集 const std::map&lt;std::pair&lt;std::string, bool&gt;, std::string&gt; K_IMAGES_META = { {std::pair&lt;std::string, bool&gt;(&quot;train-standard&quot;, false), &quot;train_large_places365standard&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;train-challenge&quot;, false), &quot;train_large_places365challenge&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;val&quot;, false), &quot;val_large&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;train-standard&quot;, true), &quot;train_256_places365standard&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;train-challenge&quot;, true), &quot;train_256_places365challenge&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;val&quot;, true), &quot;val_256&quot;}, }; 源码分析： 由于places365数据集是可以random access的，也即给定一个下标，可以直接取出该下标的图片和label，所以在数据集加载时，用户可以自定义指定sampler（加载哪些下标数据集，比如只加载前300条数据，就没必要把places365所有的数据都读入到内存里，再返回前300条），所以Places365Op继承了RandomAccessOp，主要实现LoadBuffer里的LoadTensorRow函数，LoadTensorRow函数原型为Status Places365Op::LoadTensorRow(row_id_type row_id, TensorRow *trow)，将给定下标row_id的数据放入到trow里。 其余两个相关的函数分别为： Status WalkAllFiles(); 解析图片路径和label信息，不用加载图片到内存。 Status LaunchThreadsAndInitOp(); 初始化。 数据集加载的算子逻辑是这样的，它一开始并不会加载图片到内存，它一开始只想知道一共有多少条数据，每个类别的数据对应的index是多少，所以Places365Op里有一个嵌套类Builder，Builder可以构造一个Places365Op，然后调用CountTotalRows函数来获取数据集的信息（注意，此时并不需要加载图片到内存，所以获取数据集的信息会非常快）。当获取了数据集的信息后（一共有多少条数据，每个类别的数据的下标），供给sampler使用，然后再构建Places365Op实例，并且指定要sample的数据的下标，进行数据的加载，这里使用到了多线程并行。 归根结底，这里是将数据信息的加载（非常快）和数据本身的加载（加载全部会比较慢）分开了，可以让用户指定加载哪些数据，从而不用每次都加载全部，而是直接根据下标进行加载相应的数据集。 places365_op.h /** * Copyright 2019-2021 Huawei Technologies Co., Ltd * * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #ifndef MINDSPORE_CCSRC_MINDDATA_DATASET_ENGINE_DATASETOPS_SOURCE_PLACES365_OP_H_ #define MINDSPORE_CCSRC_MINDDATA_DATASET_ENGINE_DATASETOPS_SOURCE_PLACES365_OP_H_ #include &lt;memory&gt; #include &lt;string&gt; #include &lt;algorithm&gt; #include &lt;map&gt; #include &lt;vector&gt; #include &lt;utility&gt; #include &lt;opencv2/opencv.hpp&gt; #include &lt;opencv2/core/utils/filesystem.hpp&gt; #include &quot;minddata/dataset/core/tensor.h&quot; #include &quot;minddata/dataset/engine/data_buffer.h&quot; #include &quot;minddata/dataset/engine/data_schema.h&quot; #include &quot;minddata/dataset/engine/datasetops/parallel_op.h&quot; #include &quot;minddata/dataset/engine/datasetops/source/sampler/sampler.h&quot; #include &quot;minddata/dataset/util/path.h&quot; #include &quot;minddata/dataset/util/queue.h&quot; #include &quot;minddata/dataset/util/status.h&quot; #include &quot;minddata/dataset/util/wait_post.h&quot; namespace mindspore { namespace dataset { // Forward declares template &lt;typename T&gt; class Queue; using Places365LabelPair = std::pair&lt;std::shared_ptr&lt;Tensor&gt;, uint32_t&gt;; class Places365Op : public ParallelOp, public RandomAccessOp { public: class Builder { public: // Constructor for Builder class of Places365Op Builder(); // Destructor. ~Builder() = default; // Setter method // @param int32_t rows_per_buffer // @return Builder setter method returns reference to the builder. Builder &amp;SetRowsPerBuffer(int32_t rows_per_buffer) { builder_rows_per_buffer_ = rows_per_buffer; return *this; } // Setter method // @param int32_t op_connector_size // @return Builder setter method returns reference to the builder. Builder &amp;SetOpConnectorSize(int32_t op_connector_size) { builder_op_connector_size_ = op_connector_size; return *this; } // Setter method // @param int32_t num_workers // @return Builder setter method returns reference to the builder. Builder &amp;SetNumWorkers(int32_t num_workers) { builder_num_workers_ = num_workers; return *this; } // Setter method // @param std::shared_ptr&lt;Sampler&gt; sampler // @return Builder setter method returns reference to the builder. Builder &amp;SetSampler(std::shared_ptr&lt;SamplerRT&gt; sampler) { builder_sampler_ = std::move(sampler); return *this; } // Setter method // @param const std::string &amp;dir // @return Builder &amp;SetDir(const std::string &amp;dir) { builder_dir_ = dir; return *this; } // Setter method // @param const std::string &amp;usage // @return Builder &amp;SetUsage(const std::string &amp;usage) { builder_usage_ = usage; return *this; } // Setter method // @param bool small // @return Builder &amp;SetSmall(bool small) { builder_small_ = small; return *this; } // Setter method // @param bool decode // @return Builder &amp;SetDecode(bool decode) { builder_decode_ = decode; return *this; } // Check validity of input args // @return Status The status code returned Status SanityCheck(); // The builder &quot;Build&quot; method creates the final object. // @param std::shared_ptr&lt;Places365Op&gt; *op - DatasetOp // @return Status The status code returned Status Build(std::shared_ptr&lt;Places365Op&gt; *op); private: std::string builder_dir_; std::string builder_usage_; bool builder_small_; bool builder_decode_; int32_t builder_num_workers_; int32_t builder_rows_per_buffer_; int32_t builder_op_connector_size_; std::shared_ptr&lt;SamplerRT&gt; builder_sampler_; std::unique_ptr&lt;DataSchema&gt; builder_schema_; }; // Constructor // @param std::string root - dir directory of places365 // @param const std::string &amp;usage - Usage of this dataset, can be 'train-standard', 'train-challenge' or 'val' // @param bool small - Use high resolution images or 256*256 resolution images // @param bool decode - Decode jpg format images // @param int32_t num_workers - number of workers reading images in parallel // @param int32_t rows_per_buffer - number of images (rows) in each buffer // @param int32_t queue_size - connector queue size // @param std::unique_ptr&lt;DataSchema&gt; data_schema - the schema of the mnist dataset // @param td::unique_ptr&lt;Sampler&gt; sampler - sampler tells Places365Op what to read Places365Op(const std::string &amp;root, const std::string &amp;usage, bool small, bool decode, int32_t num_workers, int32_t rows_per_buffer, int32_t queue_size, std::unique_ptr&lt;DataSchema&gt; data_schema, std::shared_ptr&lt;SamplerRT&gt; sampler); // Destructor. ~Places365Op() = default; // Worker thread pulls a number of IOBlock from IOBlock Queue, make a buffer and push it to Connector // @param int32_t worker_id - id of each worker // @return Status The status code returned Status WorkerEntry(int32_t worker_id) override; // Main Loop of Places365Op // Master thread: Fill IOBlockQueue, then goes to sleep // Worker thread: pulls IOBlock from IOBlockQueue, work on it then put buffer to mOutConnector // @return Status The status code returned Status operator()() override; // Method derived from RandomAccess Op, enable Sampler to get all ids for each class // @param (std::map&lt;uint64_t, std::vector&lt;uint64_t &gt;&gt; * map - key label, val all ids for this class // @return Status The status code returned Status GetClassIds(std::map&lt;int32_t, std::vector&lt;int64_t&gt;&gt; *cls_ids) const override; // A print method typically used for debugging // @param out // @param show_all void Print(std::ostream &amp;out, bool show_all) const override; // Function to count the number of samples in the Places365 dataset // @param dir path to the Places365 directory // @param const std::string &amp;usage - Usage of this dataset, can be 'train-standard', 'train-challenge' or 'val' // @param const bool small - Use high resolution images or 256*256 resolution images // @param const bool decode - Decode jpg format images // @param count output arg that will hold the minimum of the actual dataset size and numSamples // @return static Status CountTotalRows(const std::string &amp;dir, const std::string &amp;usage, const bool small, const bool decode, int64_t *count); // Op name getter // @return Name of the current Op std::string Name() const override { return &quot;Places365Op&quot;; } private: // Initialize Sampler, calls sampler-&gt;Init() within // @return Status The status code returned Status InitSampler(); // Load a tensor row according to a pair // @param row_id_type row_id - id for this tensor row // @param ImageLabelPair pair - &lt;imagefile,label&gt; // @param TensorRow row - image &amp; label read into this tensor row // @return Status The status code returned Status LoadTensorRow(row_id_type row_id, TensorRow *row); // @param const std::vector&lt;int64_t&gt; &amp;keys - keys in ioblock // @param std::unique_ptr&lt;DataBuffer&gt; db // @return Status The status code returned Status LoadBuffer(const std::vector&lt;int64_t&gt; &amp;keys, std::unique_ptr&lt;DataBuffer&gt; *db); // Iterate through all members in sampleIds and fill them into IOBlock. // @param std::shared_ptr&lt;Tensor&gt; sample_ids - // @param std::vector&lt;int64_t&gt; *keys - keys in ioblock // @return Status The status code returned Status TraversalSampleIds(const std::shared_ptr&lt;Tensor&gt; &amp;sample_ids, std::vector&lt;int64_t&gt; *keys); // Load the meta information of categories. // @param const std::string &amp;category_meta_name // @return Status The status code returned Status LoadCategories(const std::string &amp;category_meta_name); // Load the meta information of file infomation. // @param const std::string &amp;filelists_meta_name // @return Status The status code returned Status LoadFileLists(const std::string &amp;filelists_meta_name); // Get one piece of places365 data // @param uint32_t index Index of the datas // @param std::shared_ptr&lt;Tensor&gt; *image_tensor Store the result in image_tensor // @return Status The status code returned Status GetPlaces365DataTensor(uint32_t index, std::shared_ptr&lt;Tensor&gt; *image_tensor); // Read all files in the directory // @return Status The status code returned Status WalkAllFiles(); // Called first when function is called // @return Status The status code returned Status LaunchThreadsAndInitOp(); // reset Op // @return Status The status code returned Status Reset() override; // Private function for computing the assignment of the column name map. // @return - Status Status ComputeColMap() override; int64_t buf_cnt_; int64_t row_cnt_; int32_t rows_per_buffer_; std::unique_ptr&lt;DataSchema&gt; data_schema_; const std::string root_; // directory of image folder const std::string usage_; // can only be &quot;train-challenge&quot;, &quot;train-standard&quot; or &quot;val&quot; const bool small_; const bool decode_; std::map&lt;std::string, int&gt; categorie2id_; std::vector&lt;std::pair&lt;std::string, uint32_t&gt;&gt; image_path_label_pairs_; // std::vector&lt;Places365LabelPair&gt; image_label_pairs_; }; } // namespace dataset } // namespace mindspore #endif // MINDSPORE_CCSRC_MINDDATA_DATASET_ENGINE_DATASETOPS_SOURCE_PLACES365_OP_H_ places365_op.cc /** * Copyright 2019-2021 Huawei Technologies Co., Ltd * * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ #include &quot;minddata/dataset/engine/datasetops/source/places365_op.h&quot; #include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;iomanip&gt; #include &lt;set&gt; #include &quot;utils/ms_utils.h&quot; #include &quot;minddata/dataset/core/config_manager.h&quot; #include &quot;minddata/dataset/core/tensor_shape.h&quot; #include &quot;minddata/dataset/engine/datasetops/source/sampler/sequential_sampler.h&quot; #include &quot;minddata/dataset/engine/db_connector.h&quot; #include &quot;minddata/dataset/engine/execution_tree.h&quot; #ifndef ENABLE_ANDROID #include &quot;minddata/dataset/kernels/image/image_utils.h&quot; #else #include &quot;minddata/dataset/kernels/image/lite_image_utils.h&quot; #endif namespace mindspore { namespace dataset { const std::string K_CATEGORIES_META = &quot;categories_places365.txt&quot;; const std::map&lt;std::string, std::string&gt; K_FILE_LIST_META = { {&quot;train-standard&quot;, &quot;places365_train_standard.txt&quot;}, {&quot;train-challenge&quot;, &quot;places365_train_challenge.txt&quot;}, {&quot;val&quot;, &quot;places365_val.txt&quot;} }; const std::map&lt;std::pair&lt;std::string, bool&gt;, std::string&gt; K_IMAGES_META = { {std::pair&lt;std::string, bool&gt;(&quot;train-standard&quot;, false), &quot;train_large_places365standard&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;train-challenge&quot;, false), &quot;train_large_places365challenge&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;val&quot;, false), &quot;val_large&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;train-standard&quot;, true), &quot;train_256_places365standard&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;train-challenge&quot;, true), &quot;train_256_places365challenge&quot;}, {std::pair&lt;std::string, bool&gt;(&quot;val&quot;, true), &quot;val_256&quot;}, }; Places365Op::Builder::Builder() : builder_sampler_(nullptr), builder_usage_(&quot;train-standard&quot;), builder_small_(true), builder_decode_(true) { std::shared_ptr&lt;ConfigManager&gt; cfg = GlobalContext::config_manager(); builder_num_workers_ = cfg-&gt;num_parallel_workers(); builder_rows_per_buffer_ = cfg-&gt;rows_per_buffer(); builder_op_connector_size_ = cfg-&gt;op_connector_size(); } Status Places365Op::Builder::Build(std::shared_ptr&lt;Places365Op&gt; *ptr) { RETURN_IF_NOT_OK(SanityCheck()); if (builder_sampler_ == nullptr) { const int64_t num_samples = 0; const int64_t start_index = 0; builder_sampler_ = std::make_shared&lt;SequentialSamplerRT&gt;(start_index, num_samples); } builder_schema_ = std::make_unique&lt;DataSchema&gt;(); RETURN_IF_NOT_OK( builder_schema_-&gt;AddColumn(ColDescriptor(&quot;image&quot;, DataType(DataType::DE_UINT8), TensorImpl::kCv, 1))); TensorShape scalar = TensorShape::CreateScalar(); RETURN_IF_NOT_OK(builder_schema_-&gt;AddColumn( ColDescriptor(&quot;label&quot;, DataType(DataType::DE_UINT32), TensorImpl::kFlexible, 0, &amp;scalar))); *ptr = std::make_shared&lt;Places365Op&gt;(builder_dir_, builder_usage_, builder_small_, builder_decode_, builder_num_workers_, builder_rows_per_buffer_, builder_op_connector_size_, std::move(builder_schema_), std::move(builder_sampler_)); return Status::OK(); } Status Places365Op::Builder::SanityCheck() { const std::set&lt;std::string&gt; valid = {&quot;train-standard&quot;, &quot;train-challenge&quot;, &quot;val&quot;}; Path dir(builder_dir_); std::string err_msg; err_msg += dir.IsDirectory() == false ? &quot;Invalid parameter, MNIST path is invalid or not set, path: &quot; + builder_dir_ + &quot;.\\n&quot; : &quot;&quot;; err_msg += builder_num_workers_ &lt;= 0 ? &quot;Invalid parameter, num_parallel_workers must be greater than 0, but got &quot; + std::to_string(builder_num_workers_) + &quot;.\\n&quot; : &quot;&quot;; err_msg += valid.find(builder_usage_) == valid.end() ? &quot;Invalid parameter, usage must be 'train-standard', 'train-challenge', 'val', but got &quot; + builder_usage_ + &quot;.\\n&quot; : &quot;&quot;; return err_msg.empty() ? Status::OK() : Status(StatusCode::kMDUnexpectedError, __LINE__, __FILE__, err_msg); } Places365Op::Places365Op(const std::string &amp;root, const std::string &amp;usage, bool small, bool decode, int32_t num_workers, int32_t rows_per_buffer, int32_t queue_size, std::unique_ptr&lt;DataSchema&gt; data_schema, std::shared_ptr&lt;SamplerRT&gt; sampler) : ParallelOp(num_workers, queue_size, std::move(sampler)), root_(root), usage_(usage), small_(small), decode_(decode), buf_cnt_(0), row_cnt_(0), rows_per_buffer_(rows_per_buffer), categorie2id_({}), image_path_label_pairs_({}), data_schema_(std::move(data_schema)) { io_block_queues_.Init(num_workers, queue_size); } Status Places365Op::TraversalSampleIds(const std::shared_ptr&lt;Tensor&gt; &amp;sample_ids, std::vector&lt;int64_t&gt; *keys) { for (auto itr = sample_ids-&gt;begin&lt;int64_t&gt;(); itr != sample_ids-&gt;end&lt;int64_t&gt;(); ++itr) { if ((*itr) &gt;= num_rows_) continue; // index out of bound, skipping keys-&gt;push_back(*itr); row_cnt_++; if (row_cnt_ % rows_per_buffer_ == 0) { RETURN_IF_NOT_OK(io_block_queues_[buf_cnt_++ % num_workers_]-&gt;Add( std::make_unique&lt;IOBlock&gt;(IOBlock(*keys, IOBlock::kDeIoBlockNone)))); keys-&gt;clear(); } } return Status::OK(); } // functor that contains the main logic of Places365 op Status Places365Op::operator()() { RETURN_IF_NOT_OK(LaunchThreadsAndInitOp()); std::unique_ptr&lt;DataBuffer&gt; sampler_buffer; RETURN_IF_NOT_OK(sampler_-&gt;GetNextSample(&amp;sampler_buffer)); while (true) { // each iterator is 1 epoch std::vector&lt;int64_t&gt; keys; keys.reserve(rows_per_buffer_); while (sampler_buffer-&gt;eoe() == false) { std::shared_ptr&lt;Tensor&gt; sample_ids; RETURN_IF_NOT_OK(sampler_buffer-&gt;GetTensor(&amp;sample_ids, 0, 0)); if (sample_ids-&gt;type() != DataType(DataType::DE_INT64)) { RETURN_STATUS_UNEXPECTED(&quot;Invalid parameter, data type of Sampler Tensor isn't int64, got &quot; + sample_ids-&gt;type().ToString()); } RETURN_IF_NOT_OK(TraversalSampleIds(sample_ids, &amp;keys)); RETURN_IF_NOT_OK(sampler_-&gt;GetNextSample(&amp;sampler_buffer)); } if (keys.empty() == false) { RETURN_IF_NOT_OK(io_block_queues_[(buf_cnt_++) % num_workers_]-&gt;Add( std::make_unique&lt;IOBlock&gt;(IOBlock(keys, IOBlock::kDeIoBlockNone)))); } if (IsLastIteration()) { RETURN_IF_NOT_OK( io_block_queues_[(buf_cnt_++) % num_workers_]-&gt;Add(std::make_unique&lt;IOBlock&gt;(IOBlock::kDeIoBlockFlagEoe))); RETURN_IF_NOT_OK( io_block_queues_[(buf_cnt_++) % num_workers_]-&gt;Add(std::make_unique&lt;IOBlock&gt;(IOBlock::kDeIoBlockFlagEof))); for (int32_t i = 0; i &lt; num_workers_; ++i) { RETURN_IF_NOT_OK( io_block_queues_[i]-&gt;Add(std::make_unique&lt;IOBlock&gt;(std::vector&lt;int64_t&gt;(), IOBlock::kDeIoBlockNone))); } return Status::OK(); } else { RETURN_IF_NOT_OK( io_block_queues_[(buf_cnt_++) % num_workers_]-&gt;Add(std::make_unique&lt;IOBlock&gt;(IOBlock::kDeIoBlockFlagEoe))); } if (epoch_sync_flag_) { // If epoch_sync_flag_ is set, then master thread sleeps until all the worker threads have finished their job for // the current epoch. RETURN_IF_NOT_OK(WaitForWorkers()); } // If not the last repeat, self-reset and go to loop again. if (!IsLastIteration()) { RETURN_IF_NOT_OK(Reset()); RETURN_IF_NOT_OK(sampler_-&gt;GetNextSample(&amp;sampler_buffer)); } UpdateRepeatAndEpochCounter(); } } // contains the logic of pulling a IOBlock from IOBlockQueue, load a buffer and push the buffer to out_connector_ Status Places365Op::WorkerEntry(int32_t worker_id) { TaskManager::FindMe()-&gt;Post(); int64_t buffer_id = worker_id; std::unique_ptr&lt;IOBlock&gt; iOBlock; RETURN_IF_NOT_OK(io_block_queues_[worker_id]-&gt;PopFront(&amp;iOBlock)); while (iOBlock != nullptr) { if (iOBlock-&gt;wait() == true) { // Sync io_block is a signal that master thread wants us to pause and sync with other workers. // The last guy who comes to this sync point should reset the counter and wake up the master thread. if (++num_workers_paused_ == num_workers_) { wait_for_workers_post_.Set(); } } else if (iOBlock-&gt;eoe() == true) { RETURN_IF_NOT_OK(out_connector_-&gt;Add(worker_id, std::make_unique&lt;DataBuffer&gt;(0, DataBuffer::kDeBFlagEOE))); buffer_id = worker_id; } else if (iOBlock-&gt;eof() == true) { RETURN_IF_NOT_OK(out_connector_-&gt;Add(worker_id, std::make_unique&lt;DataBuffer&gt;(0, DataBuffer::kDeBFlagEOF))); } else { std::vector&lt;int64_t&gt; keys; RETURN_IF_NOT_OK(iOBlock-&gt;GetKeys(&amp;keys)); if (keys.empty() == true) return Status::OK(); // empty key is a quit signal for workers std::unique_ptr&lt;DataBuffer&gt; db = std::make_unique&lt;DataBuffer&gt;(buffer_id, DataBuffer::kDeBFlagNone); RETURN_IF_NOT_OK(LoadBuffer(keys, &amp;db)); RETURN_IF_NOT_OK(out_connector_-&gt;Add(worker_id, std::move(db))); buffer_id += num_workers_; } RETURN_IF_NOT_OK(io_block_queues_[worker_id]-&gt;PopFront(&amp;iOBlock)); } RETURN_STATUS_UNEXPECTED(&quot;Unexpected nullptr received in worker.&quot;); } Status Places365Op::LoadTensorRow(row_id_type row_id, TensorRow *trow) { std::shared_ptr&lt;Tensor&gt; image, label; // make a copy of cached tensor RETURN_IF_NOT_OK(GetPlaces365DataTensor(row_id, &amp;image)); RETURN_IF_NOT_OK(Tensor::CreateScalar(image_path_label_pairs_[row_id].second, &amp;label)); (*trow) = TensorRow(row_id, {std::move(image), std::move(label)}); // trow-&gt;setPath({image_path_[row_id], label_path_[row_id]}); return Status::OK(); } // Looping over LoadTensorRow to make 1 DataBuffer. 1 function call produces 1 buffer Status Places365Op::LoadBuffer(const std::vector&lt;int64_t&gt; &amp;keys, std::unique_ptr&lt;DataBuffer&gt; *db) { std::unique_ptr&lt;TensorQTable&gt; deq = std::make_unique&lt;TensorQTable&gt;(); TensorRow trow; for (const int64_t &amp;key : keys) { RETURN_IF_NOT_OK(this-&gt;LoadTensorRow(key, &amp;trow)); deq-&gt;push_back(std::move(trow)); } (*db)-&gt;set_tensor_table(std::move(deq)); return Status::OK(); } void Places365Op::Print(std::ostream &amp;out, bool show_all) const { if (!show_all) { // Call the super class for displaying any common 1-liner info ParallelOp::Print(out, show_all); // Then show any custom derived-internal 1-liner info for this op out &lt;&lt; &quot;\\n&quot;; } else { // Call the super class for displaying any common detailed info ParallelOp::Print(out, show_all); // Then show any custom derived-internal stuff out &lt;&lt; &quot;\\nNumber of rows:&quot; &lt;&lt; num_rows_ &lt;&lt; &quot;\\nPlaces365 Directory: &quot; &lt;&lt; root_ &lt;&lt; &quot;\\n\\n&quot;; } } // Reset Sampler and wakeup Master thread (functor) Status Places365Op::Reset() { MS_LOG(DEBUG) &lt;&lt; Name() &lt;&lt; &quot; performing a self-reset.&quot;; RETURN_IF_NOT_OK(sampler_-&gt;ResetSampler()); row_cnt_ = 0; return Status::OK(); } // hand shake with Sampler, allow Sampler to call RandomAccessOp's functions to get NumRows Status Places365Op::InitSampler() { RETURN_IF_NOT_OK(sampler_-&gt;HandshakeRandomAccessOp(this)); return Status::OK(); } // Derived from RandomAccessOp Status Places365Op::GetClassIds(std::map&lt;int32_t, std::vector&lt;int64_t&gt;&gt; *cls_ids) const { if (cls_ids == nullptr || !cls_ids-&gt;empty() || image_path_label_pairs_.empty()) { if (image_path_label_pairs_.empty()) { RETURN_STATUS_UNEXPECTED(&quot;No image found in dataset, please check if Op read images successfully or not.&quot;); } else { RETURN_STATUS_UNEXPECTED( &quot;Map for storaging image-index pair is nullptr or has been set in other place,&quot; &quot;it must be empty before using GetClassIds.&quot;); } } for (size_t i = 0; i &lt; image_path_label_pairs_.size(); ++i) { (*cls_ids)[image_path_label_pairs_[i].second].push_back(i); } for (auto &amp;pair : (*cls_ids)) { pair.second.shrink_to_fit(); } return Status::OK(); } // Load the meta information of categories. // @param const std::string &amp;category_meta_name // @return Status The status code returned Status Places365Op::LoadCategories(const std::string &amp;category_meta_name){ std::ifstream reader(category_meta_name); // std::cout &lt;&lt; category_meta_name &lt;&lt; std::endl; CHECK_FAIL_RETURN_UNEXPECTED(!reader.fail(), category_meta_name + &quot; File not exists!&quot;); std::string path; int label; while (reader &gt;&gt; path &gt;&gt; label){ categorie2id_.insert({path, label}); } reader.close(); return Status::OK(); } // Load the meta information of file infomation. // @param const std::string &amp;filelists_meta_name // @return Status The status code returned Status Places365Op::LoadFileLists(const std::string &amp;filelists_meta_name){ // std::cout &lt;&lt; filelists_meta_name &lt;&lt; std::endl; std::ifstream reader(filelists_meta_name); CHECK_FAIL_RETURN_UNEXPECTED(!reader.fail(), filelists_meta_name + &quot; File not exists!&quot;); std::string path; int label; std::string folder_path = cv::utils::fs::join(root_, K_IMAGES_META.at(std::make_pair(usage_, small_))); image_path_label_pairs_.clear(); while (reader &gt;&gt; path &gt;&gt; label){ image_path_label_pairs_.push_back({cv::utils::fs::join(folder_path, path), label}); } reader.close(); return Status::OK(); } // Get one piece of places365 data // @param uint32_t index Index of the datas // @param std::shared_ptr&lt;Tensor&gt; *image_tensor Store the result in image_tensor // @return Status The status code returned Status Places365Op::GetPlaces365DataTensor(uint32_t index, std::shared_ptr&lt;Tensor&gt; *image_tensor){ std::string file_path = image_path_label_pairs_[index].first; RETURN_IF_NOT_OK(Tensor::CreateFromFile(file_path, image_tensor)); if(decode_){ Status rc = Decode(*image_tensor, image_tensor); if (rc.IsError()) { *image_tensor = nullptr; std::string err_msg = &quot;Invalid data, failed to decode image: &quot; + file_path; return Status(StatusCode::kMDUnexpectedError, __LINE__, __FILE__, err_msg); } } return Status::OK(); } // Read all files in the directory // @return Status The status code returned Status Places365Op::WalkAllFiles(){ RETURN_IF_NOT_OK(LoadCategories(cv::utils::fs::join(root_, K_CATEGORIES_META))); RETURN_IF_NOT_OK(LoadFileLists(cv::utils::fs::join(root_, K_FILE_LIST_META.at(usage_)))); num_rows_ = image_path_label_pairs_.size(); if (num_rows_ == 0) { RETURN_STATUS_UNEXPECTED( &quot;Invalid data, no valid data matching the dataset API Places365Dataset. Please check file path or dataset API.&quot;); } return Status::OK(); } // Called first when function is called // @return Status The status code returned Status Places365Op::LaunchThreadsAndInitOp(){ if (tree_ == nullptr) { RETURN_STATUS_UNEXPECTED(&quot;Pipeline init failed, Execution tree not set.&quot;); } RETURN_IF_NOT_OK(io_block_queues_.Register(tree_-&gt;AllTasks())); RETURN_IF_NOT_OK(wait_for_workers_post_.Register(tree_-&gt;AllTasks())); RETURN_IF_NOT_OK( tree_-&gt;LaunchWorkers(num_workers_, std::bind(&amp;Places365Op::WorkerEntry, this, std::placeholders::_1), &quot;&quot;, id())); TaskManager::FindMe()-&gt;Post(); RETURN_IF_NOT_OK(this-&gt;WalkAllFiles()); RETURN_IF_NOT_OK(this-&gt;InitSampler()); // handle shake with sampler return Status::OK(); } Status Places365Op::CountTotalRows(const std::string &amp;dir, const std::string &amp;usage, const bool small, const bool decode, int64_t *count) { // the logic of counting the number of samples is copied from ParseMnistData() and uses CheckReader() std::shared_ptr&lt;Places365Op&gt; op; *count = 0; RETURN_IF_NOT_OK(Builder().SetDir(dir).SetUsage(usage).SetSmall(small).SetDecode(decode).Build(&amp;op)); RETURN_IF_NOT_OK(op-&gt;WalkAllFiles()); for (size_t i = 0; i &lt; op-&gt;image_path_label_pairs_.size(); ++i) { CHECK_FAIL_RETURN_UNEXPECTED(cv::utils::fs::exists(op-&gt;image_path_label_pairs_[i].first), &quot;Invalid data, num of images is not equal to num of labels.&quot;); } *count = op-&gt;image_path_label_pairs_.size(); return Status::OK(); } Status Places365Op::ComputeColMap() { // set the column name map (base class field) if (column_name_id_map_.empty()) { for (int32_t i = 0; i &lt; data_schema_-&gt;NumColumns(); ++i) { column_name_id_map_[data_schema_-&gt;column(i).name()] = i; } } else { MS_LOG(WARNING) &lt;&lt; &quot;Column name map is already set!&quot;; } return Status::OK(); } } // namespace dataset } // namespace mindspore ","link":"https://yangyueren.github.io/post/hua-wei-mindspore-shu-ju-ji-jia-zai-suan-zi-kai-fa/"},{"title":"2021年3月晨读记录","content":"感受 三月初在西溪田家炳书院和李、刘、严等同学开始晨读，早上8点到8点25学习英语，之后用英语讨论一个topic。 主要收获有三点：首先是改正作息习惯，每天7点30起床，因为自己是晨读的发起人，不敢厚着脸皮每次都请假赖床；其次是恢复英语的学习习惯，在大二时就有前辈告诫我英语非常重要，时至今日英语听说读写的能力仍有很大提高空间；最后是和不同专业的同学交流想法，会开阔自己的思维，例如了解了第四纪地质学的研究方法。 每日讨论 以下Topic部分观点来自李、刘、严同学。 Topic：是否走出舒适圈 什么是舒适圈，舒适圈一定是坏的吗？ 对此有两个理解：一种理解是咸鱼的状态，害怕新事物失去掌控，不敢去改变也不想去改变的状态；另一种理解是舒适圈是让自己开心和舒服的一种生活状态，不一定是坏的，比如选择大城市生活还是小城市安逸。 需要逐步扩大舒适圈，例如扩大自己的朋友圈，认识更多的人，让自己接触未知的事物，但是如果让自己不舒服了，要及时止损。 Topic：家乡 重庆：涪陵，长江乌江交汇之处；地形崎岖，容易迷路；推荐《江城》，以作者在涪陵的两年支教生活为主线，用纪实的语言介绍了涪陵周边的生活图景和城市状态。 宁夏：塞上江南，羊肉（滩羊排），宗教，地广人稀 Topic：女权 女权有两种表现形式，机会平等和结果平等，机会平等是指男女拥有相同的入门券，但是还需要通过竞争进行选拔，结果平等是指给男女分配同样的名额，男女分开竞争。以上两种都是可以接受的，但是存在一些人两个都想要，所以被喷。我们身边的女生更多推崇机会平等的女权，大家都依靠自己的努力得到想要的结果（归因于大学里的竞争更多体现在智力，而不是体力，所以男女平等的基础得到了保证）。 Topic：进行专业介绍 学习了第四地质地理学，寻找河流； 学习了心理学和道德的区别： Moral psychology grew out of moral philosophy, a field dominated by normative ethics, which studies how people outght to act and why certain acts are right or wrong. Morality is an adaption, built upon emotions that are themselves adaptive, with specific moral codes emerging via gene-culture coevolution. Topic：闲暇时间的安排 和朋友聚餐，运动，拍照等，大家的闲暇时间安排大同小异。 后续讨论到男女体质的差异，同样的运动量，男生更容易增长肌肉；对女性的body shame。 Activity：周六爬山 黄龙洞-蛤蟆峰-北山街；路上聊到穆斯林的一些宗教信仰，斋月（每天东方刚刚开始发亮至日落期间不饮食，除了患病者、旅行者、乳婴、孕妇、哺乳妇、产妇、正在行经的妇女以及作战的士兵外）。 伊斯兰教：以《古兰经》和圣训作为教导，信仰造物主安拉，认为人生的唯一目的是追随安拉，伊斯兰意为“追随”，穆斯林是伊斯兰的字根，意为“追随者”。先知有亚伯拉罕、摩西、耶稣、穆罕默德。 宗教起源整理： · 犹太教 亚伯拉罕 - 摩西出埃及记 - 耶稣（公元元年） 这段历史是《塔纳赫》，又称《旧约》 · 基督教 承接犹太教的《塔纳赫》，认为神是亚伯拉罕（上帝） - 耶稣布道、《新约》 - 公元393年罗马帝国确立基督教为唯一信仰 - 大规模扩散 · 伊斯兰教 承接犹太教的《塔纳赫》，认为神是亚伯拉罕（真主安拉） - 公元610年穆罕默德传教、《古兰经》 最早是犹太教，上帝用七天创造世界，和亚伯拉罕立约，公元前1250年摩西出埃及。直到公元元年，犹太人耶稣诞生，人称上帝之子，四处布道传递上帝福音，他的信徒将耶稣的故事写成书向非犹太人传播，衍生出基督教。耶稣出生前的历史被记录于《塔纳赫》，也就是《旧约》，耶稣的故事被记录为《新约》。313年罗马皇帝君士坦丁合法化基督教，基督教爆发式扩散，392年基督教成为罗马帝国唯一信仰（类似罢黜百家，独尊儒术）。 公元610年，40岁的穆罕默德受到真主启示，开始宣传伊斯兰教，他所说的话，被记录为《古兰经》，穆斯林认为《古兰经》是神通过穆罕默德之口传到人间的话语。这里的神也是犹太教最早的亚伯拉罕，伊斯兰教认同《塔纳赫》的前五本，比如亚伯拉罕，摩西出埃及记等。但是穆斯林认为耶稣死后复活的故事是其他教编出来的，与基督教出现分歧，所以虽然伊斯兰教和基督教同源，但是都认为对方是异教徒。 经济学人：国外情报机构使用AI用于信息解密 经济学人的这篇《人工智能“投身”情报界，让你无处遁形》讲述spies和intelligence agencies使用AI的场景： 在冷战时期，美国国安局NSA和英国政府通信总部GCHQ开始使用机器转录苏联的窃听电话 目前AI可以用于发现可疑的金融交易链，找出涉嫌参与非法买卖核武器材料的公司 谷歌母公司Alphabet和美国前国防部长领导美国国家安全委员会人工智能小组，到2030年，美国17家间谍机构将建立起持续学习分析引擎的联合架构，分析人工情报到卫星图像等多种信息。 目前存在的问题： 西方国家更加注重私人数据的隐私性 要考虑系统偏见，比如语音识别软件对某些群体是否比对其他群体更有效（美国很重视种族歧视问题orz） 来自无人机、侦查卫星、截获的电话等数据是未标注的数据，需要大量人工标注（有多少人工就有多少智能orz） 每日英语 素材来自 公众号 TeacherGwen 和 每日英语听力 经济学人。 Our love is six feet under I can't help but wonder If our grave was watered by the rain 取自《六尺之下》(six feet under) 上穷下落见黄泉，两处茫茫皆不见 And even though I'm in pain, it'worth sticking around to make my little corner of the world a slightly better place. I'm just a little bit caught in the middle 左右为难 Life is a maze and love is a riddle 生活是座迷宫 As Yellow Crane Tower in the west my old friend says farewell; In the mist and flowers of spring he goes down to Yangzhou; 故人西辞黄鹤楼，烟花三月下扬州 The film was low on science and high on fiction. Although fossils preserve the gross physical features of extinct animals, they are silent about many crucial details that even an incomplete genome can help to fill in. You cannot reason with a tiger when your head is in its mouth.（丘吉尔的讲话） We have to give Mother Nature tools she needs to use her intelligence to self-heal. ","link":"https://yangyueren.github.io/post/2021-nian-3-yue-chen-du-ji-lu/"},{"title":"MIT6.S081 syscall","content":"syscall的原理： 在shell中，当输入某个命令，比如sysinfo，shell fork出一个进程调用sysinfo.c处理sysinfo命令，此时还处于user space；在sysinfo.c的main函数中，会进行系统调用，比如系统调用sysinfo，read，kill等，这些系统调用是通过usys.pl脚本，把sysinfo通过ecall跳转到kernel的部分。 sub entry { my $name = shift; print &quot;.global $name\\n&quot;; print &quot;${name}:\\n&quot;; print &quot; li a7, SYS_${name}\\n&quot;; print &quot; ecall\\n&quot;; print &quot; ret\\n&quot;; } entry(&quot;fork&quot;); entry(&quot;exit&quot;); entry(&quot;wait&quot;); entry(&quot;pipe&quot;); entry(&quot;sysinfo&quot;); 在kernel的syscall里面查SYS_sysinfo的函数位置，如何查找位置呢，kernel/syscall.c有一个 static uint64 (*syscalls[])(void) = { [SYS_fork] sys_fork, [SYS_exit] sys_exit, [SYS_wait] sys_wait, [SYS_pipe] sys_pipe } 可以通过SYSinfo找到对应的sys_sysinfo kernel中的函数，进行操作。 System call tracing 添加一个trace的系统调用 sysproc.c uint64 sys_trace(void) { int mask; if(argint(0, &amp;mask) &lt; 0) return -1; myproc()-&gt;trace_mask = mask; //进程信息中记录mask return 0; } proc.h // Per-process state struct proc { struct spinlock lock; // p-&gt;lock must be held when using these: enum procstate state; // Process state struct proc *parent; // Parent process void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed int xstate; // Exit status to be returned to parent's wait int pid; // Process ID // these are private to the process, so p-&gt;lock need not be held. uint64 kstack; // Virtual address of kernel stack uint64 sz; // Size of process memory (bytes) pagetable_t pagetable; // User page table struct trapframe *trapframe; // data page for trampoline.S struct context context; // swtch() here to run process struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory char name[16]; // Process name (debugging) int trace_mask; //记录trace mask }; syscall.c static uint64 (*syscalls[])(void) = { [SYS_fork] sys_fork, ... [SYS_sysinfo] sys_sysinfo, }; char* syscall_name[23] = { &quot;0&quot;, &quot;syscall fork&quot;, &quot;syscall exit&quot;, &quot;syscall wait&quot;, &quot;syscall pipe&quot;, &quot;syscall read&quot;, &quot;syscall kill&quot;, &quot;syscall exec&quot;, &quot;syscall fstat&quot;, &quot;syscall chdir&quot;, &quot;syscall dup&quot;, &quot;syscall getpid&quot;, &quot;syscall sbrk&quot;, &quot;syscall sleep&quot;, &quot;syscall uptime&quot;, &quot;syscall open&quot;, &quot;syscall write&quot;, &quot;syscall mknod&quot;, &quot;syscall unlink&quot;, &quot;syscall link&quot;, &quot;syscall mkdir&quot;, &quot;syscall close&quot;, &quot;syscall trace&quot;, }; void syscall(void) { int num; struct proc *p = myproc(); num = p-&gt;trapframe-&gt;a7; if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) { p-&gt;trapframe-&gt;a0 = syscalls[num](); int trace_mask = p-&gt;trace_mask; //判断是否对该syscall显示trace if(trace_mask &gt;&gt; num &amp; 0x1){ printf(&quot;%d: %s -&gt; %d\\n&quot;, p-&gt;pid, syscall_name[num], p-&gt;trapframe-&gt;a0); } } else { printf(&quot;%d %s: unknown sys call %d\\n&quot;, p-&gt;pid, p-&gt;name, num); p-&gt;trapframe-&gt;a0 = -1; } } 处理子进程，让mask能够继承 proc.c int fork(void) { int i, pid; struct proc *np; struct proc *p = myproc(); // Allocate process. if((np = allocproc()) == 0){ return -1; } // Copy user memory from parent to child. if(uvmcopy(p-&gt;pagetable, np-&gt;pagetable, p-&gt;sz) &lt; 0){ freeproc(np); release(&amp;np-&gt;lock); return -1; } np-&gt;sz = p-&gt;sz; np-&gt;parent = p; // copy saved user registers. *(np-&gt;trapframe) = *(p-&gt;trapframe); // Cause fork to return 0 in the child. np-&gt;trapframe-&gt;a0 = 0; // increment reference counts on open file descriptors. for(i = 0; i &lt; NOFILE; i++) if(p-&gt;ofile[i]) np-&gt;ofile[i] = filedup(p-&gt;ofile[i]); np-&gt;cwd = idup(p-&gt;cwd); safestrcpy(np-&gt;name, p-&gt;name, sizeof(p-&gt;name)); pid = np-&gt;pid; np-&gt;state = RUNNABLE; np-&gt;trace_mask = p-&gt;trace_mask; //传递trace_mask release(&amp;np-&gt;lock); return pid; } Sysinfo 打印出空闲的内存和未使用的进程 · 如何获取空闲内存：遍历kmem.freelist，每个元素是一个page · 如何获取未使用的进程：遍历proc.c中的struct proc proc[NPROC]; · 如何将上述信息从内核传递到user space：copyout sysproc.c uint64 sys_sysinfo(void) { struct sysinfo info; uint64 addr; // 获取用户态传入的sysinfo结构体 if (argaddr(0, &amp;addr) &lt; 0) return -1; struct proc* p = myproc(); info.freemem = free_memory(); info.nproc = proc_unused_num(); //copyout 传入user pagetable，info结构体的user space地址，把kernel中的info copy过去 if (copyout(p-&gt;pagetable, addr, (char*)&amp;info, sizeof(info)) &lt; 0) return -1; return 0; } ","link":"https://yangyueren.github.io/post/mit6s081-syscall/"},{"title":"MIT6.S081 util","content":"第一个lab是熟悉xv6的system calls sleep： easy难度 在makefile的UPROGS添加$U/_sleep 在user/sleep.c中写以下代码： #include &quot;kernel/types.h&quot; #include &quot;kernel/stat.h&quot; #include &quot;user/user.h&quot; int main(int argc, char *argv[]) { if(argc != 2){ fprintf(2, &quot;sleep needs an int as param.\\n&quot;); exit(1); } int i = atoi(argv[1]); sleep(i); exit(0); } pingpong：利用pipe在父子进程间通信（利用子进程会继承父进程的打开文件符） #include &quot;kernel/types.h&quot; #include &quot;kernel/stat.h&quot; #include &quot;user/user.h&quot; int main(int argc, char *argv[]) { if(argc &gt; 1){ fprintf(2, &quot;ping-pong doesn't need params\\n&quot;); exit(1); } char v = 0; int parent[2]; int child[2]; pipe(parent); pipe(child); if(fork() == 0){ //child close(child[1]); close(parent[0]); read(child[0], &amp;v, 1); if(v==0){ printf(&quot;%d: received ping\\n&quot;, getpid()); }else{ exit(1); } v = 1; write(parent[1], &amp;v, 1); close(child[0]); close(parent[1]); }else{ //parent close(child[0]); close(parent[1]); write(child[1], &amp;v, 1); read(parent[0], &amp;v, 1); if(v==1){ printf(&quot;%d: received pong\\n&quot;, getpid()); }else{ exit(1); } close(parent[0]); close(child[1]); } exit(0); } primes：利用fork出来的进程树，对数据进行过滤 及时关闭用不到的fd #include &quot;kernel/types.h&quot; #include &quot;kernel/stat.h&quot; #include &quot;kernel/param.h&quot; #include &quot;user/user.h&quot; /* 解题思路： buffer的作用是保存这轮不能被筛除的数 */ int main(int argc, char *argv[]) { int fd[2]; int buffer[36]; int cnt = 0; for (int i = 2; i &lt; 36; i++) { buffer[cnt++] = i; } while (cnt &gt; 0) { pipe(fd); if(fork() == 0) { close(fd[1]); int base = 0; cnt = -1; int v; while (read(fd[0], &amp;v, sizeof(v))) { if(cnt == -1){ base = v; cnt = 0; }else if(v % base != 0){ buffer[cnt++] = v; } } close(fd[0]); printf(&quot;prime %d\\n&quot;, base); } else { close(fd[0]); for (int i = 0; i &lt; cnt; i++) { write(fd[1], &amp;buffer[i], sizeof(buffer[i])); } close(fd[1]); wait(0); break; //父进程跳出while循环 } } exit(0); } find：利用fstat查看fd的元信息，如果是file，则拿到文件名，如果是directory，则读取其中的struct dirent #include &quot;kernel/types.h&quot; #include &quot;kernel/stat.h&quot; #include &quot;user/user.h&quot; #include &quot;kernel/fs.h&quot; // extract b from ./a/b void extractname(char *path, char *buf) { char *p = path + strlen(path); while(*--p != '/'){ } strcpy(buf, p+1); } void find(char *path, char *name) { char buf[512], *p; int fd; struct dirent de; struct stat st; if((fd = open(path, 0)) &lt; 0){ fprintf(2, &quot;find: cannot open %s\\n&quot;, path); return; } //fstat是查看该fd的元信息 if(fstat(fd, &amp;st) &lt; 0){ fprintf(2, &quot;find: cannot stat %s\\n&quot;, path); close(fd); return; } switch(st.type){ case T_FILE: extractname(path, buf); if(strcmp(buf, name) == 0){ printf(&quot;%s\\n&quot;, path); } break; case T_DIR: if(strlen(path) + 1 + DIRSIZ + 1 &gt; sizeof buf){ printf(&quot;find: path too long\\n&quot;); break; } strcpy(buf, path); p = buf+strlen(buf); *p++ = '/'; //文件夹也是一个file，从里面会逐个读取文件夹下的内容，每次读一个struct dirent大小 while(read(fd, &amp;de, sizeof(de)) == sizeof(de)){ if(de.inum == 0) continue; memmove(p, de.name, DIRSIZ); p[DIRSIZ] = 0; if(stat(buf, &amp;st) &lt; 0){ printf(&quot;find: cannot stat %s\\n&quot;, buf); continue; } // printf(&quot;debug %s\\n&quot;, buf); /* 出现递归 debug ./. debug ././. debug ./././. debug ././././. */ char *check = buf + strlen(buf); while(*check != '/') check--; check++; if(strcmp(check, &quot;.&quot;) == 0) continue; if(strcmp(check, &quot;..&quot;) == 0) continue; find(buf, name); // printf(&quot;%s %d %d %d\\n&quot;, fmtname(buf), st.type, st.ino, st.size); } break; } close(fd); } int main(int argc, char *argv[]) { if(argc &lt; 3){ fprintf(2, &quot;find need at least 3 params\\n&quot;); exit(1); } find(argv[1], argv[2]); exit(0); } xargs：把上一个命令的输出作为下一个命令的输入参数 $ echo hello too | xargs echo bye bye hello too solution: #include &quot;kernel/types.h&quot; #include &quot;kernel/stat.h&quot; #include &quot;kernel/param.h&quot; #include &quot;user/user.h&quot; int main(int argc, char *argv[]) { char *args[MAXARG]; int ini_arg_num = 0; char buf[256] = {0}; // printf(&quot;argc %d\\n&quot;, argc); for(int i=1; i&lt;argc; ++i){ if(strcmp(argv[i], &quot;-n&quot;) == 0 &amp;&amp; i==1){ ++i; }else{ args[ini_arg_num++] = argv[i]; // printf(&quot;%d %s\\n&quot;, ini_arg_num-1, argv[i]); } } /* 这里有问题 无法解析\\n $ echo &quot;1\\n2&quot; | xargs -n 1 echo line &quot;1\\n2&quot; line &quot;1\\n2&quot; */ while(gets( buf, sizeof(buf))){ if(strlen(buf) &lt; 1) break; // printf(&quot;%d\\n%s&quot;, strlen(buf), buf); buf[strlen(buf)-1] = 0; //清除gets读入的\\n // printf(&quot;%s\\n&quot;, buf); int arg_num = ini_arg_num; char *p = buf; while (*p) { while ((*p == ' ') &amp;&amp; *p) *p++ = 0; if(*p) args[arg_num++] = p; while ((*p != ' ') &amp;&amp; *p) p++; } if(arg_num &gt;= MAXARG) fprintf(2, &quot;too many args\\n&quot;); if(arg_num &lt; 1) fprintf(2, &quot;too few args for xargs\\n&quot;); args[arg_num] = 0; if(fork() == 0){ // printf(&quot;%s\\n&quot;, args[0]); // printf(&quot;%s %s %s\\n&quot;, args[1], args[2], args[3]); exec(args[0], args); exit(0); }else{ wait(0); } } exit(0); } ","link":"https://yangyueren.github.io/post/mit6s081-util/"},{"title":"C++ unique_lock future condition_variable","content":"多线程的一些基础语法。 std::unique_lock 使用std::unique_lock 比std::lock_guard更加灵活：std::lock_guard 不能显式的调用 lock 和 unlock，而 std::unique_lock 可以在声明后的任意位 置调用，可以缩小锁的作用范围，提供更高的并发度。 #include &lt;iostream&gt; #include &lt;mutex&gt; #include &lt;thread&gt; using namespace std; int v = 1; void critical_sectin(int change_v){ static mutex mtx; std::this_thread::sleep_for(std::chrono::milliseconds(change_v)); std::unique_lock&lt;std::mutex&gt; lock(mtx); v = change_v; std::cout &lt;&lt; v &lt;&lt; std::endl; lock.unlock(); change_v++; lock.lock(); v = change_v; std::cout &lt;&lt; v &lt;&lt; std::endl; } int main(){ std::this_thread::sleep_for(std::chrono::milliseconds(1000)); std::thread t1(critical_sectin, 590); std::thread t2(critical_sectin, 66); t1.join(); t2.join(); return 0; } std::future 对线程的返回结果进行封装 #include &lt;iostream&gt; #include &lt;mutex&gt; #include &lt;thread&gt; #include &lt;future&gt; using namespace std; int main(){ std::packaged_task&lt;int(int)&gt; task([](int a) -&gt; int{ std::cout &lt;&lt; &quot;inside packaged_task &quot; &lt;&lt; a &lt;&lt; std::endl; return a; }); std::future&lt;int&gt; result = task.get_future(); std::thread(std::move(task), 8).detach(); //创建thread，传入package_task的参数 result.wait(); std::cout &lt;&lt; result.get() &lt;&lt; std::endl; return 0; } std::condition_variable 用于同步，解决死锁 #include &lt;iostream&gt; #include &lt;mutex&gt; #include &lt;thread&gt; #include &lt;future&gt; #include &lt;condition_variable&gt; #include &lt;queue&gt; #include &lt;string&gt; using namespace std; int main(){ std::condition_variable cv; std::mutex mtx; std::queue&lt;int&gt; produced_nums; bool notify = false; auto producer = [&amp;](){ for (int i=1; ; i++){ std::this_thread::sleep_for(std::chrono::milliseconds(900)); std::unique_lock&lt;mutex&gt; lock(mtx); std::cout &lt;&lt; &quot;producing &quot; &lt;&lt; i &lt;&lt; std::endl; produced_nums.push(i); notify = true; cv.notify_all(); } }; auto consumer = [&amp;](int csid){ while (true){ unique_lock&lt;mutex&gt; lock(mtx); while (!notify){ cv.wait(lock); } std::this_thread::sleep_for(std::chrono::milliseconds(1000)); std::cout &lt;&lt; csid &lt;&lt; &quot; lock success&quot; &lt;&lt; std::endl; if (!produced_nums.empty()){ auto result = produced_nums.front(); produced_nums.pop(); std::cout &lt;&lt; &quot;consumer &quot; &lt;&lt; csid &lt;&lt; &quot; : &quot; &lt;&lt; result &lt;&lt; &quot; &quot; &lt;&lt; produced_nums.size() &lt;&lt; std::endl; } notify = false; } }; thread produce(producer); vector&lt;thread&gt; pool; for (int i = 0; i &lt; 10; ++i) { pool.push_back(thread(consumer, i)); } produce.join(); for (int i = 0; i &lt; 10; ++i) { pool[i].join(); } return 0; } condition_variable需要mutex和condition两个变量，在cv.wait(lock)后，需要检查条件是否满足（因为存在假唤醒）。 consumer中wait被signal之后的过程： 首先要拿到lock，然后cv.wait(lock, {return is_ready;});之后，线程开始休眠，被加入一个唤醒队列，同时释放锁。 cv.notify_all()之后，所有在wait的consumer线程被唤醒，然后开始lock，注意，如果mutex此时是被locked的，这些线程也不会再休眠了，会一直尝试加锁，直到加锁成功，进入临界区。 官方样例： #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;thread&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; std::mutex m; std::condition_variable cv; std::string data; bool ready = false; bool processed = false; void worker_thread() { // Wait until main() sends data std::unique_lock&lt;std::mutex&gt; lk(m); cv.wait(lk, []{return ready;}); // after the wait, we own the lock. std::cout &lt;&lt; &quot;Worker thread is processing data\\n&quot;; data += &quot; after processing&quot;; // Send data back to main() processed = true; std::cout &lt;&lt; &quot;Worker thread signals data processing completed\\n&quot;; // Manual unlocking is done before notifying, to avoid waking up // the waiting thread only to block again (see notify_one for details) lk.unlock(); cv.notify_one(); } int main() { std::thread worker(worker_thread); data = &quot;Example data&quot;; // send data to the worker thread { std::lock_guard&lt;std::mutex&gt; lk(m); ready = true; std::cout &lt;&lt; &quot;main() signals data ready for processing\\n&quot;; } cv.notify_one(); // wait for the worker { std::unique_lock&lt;std::mutex&gt; lk(m); cv.wait(lk, []{return processed;}); } std::cout &lt;&lt; &quot;Back in main(), data = &quot; &lt;&lt; data &lt;&lt; '\\n'; worker.join(); } output: main() signals data ready for processing Worker thread is processing data Worker thread signals data processing completed Back in main(), data = Example data after processing ","link":"https://yangyueren.github.io/post/c-unique_lock-future-condition_variable/"},{"title":"C++ T&&推导T的类型","content":"T&amp;&amp;需要推导T的类型时的规则是什么？ 为什么最好用 auto&amp;&amp;的形式？ 非常量左值引用不能绑定右值 常量左值引用可以绑定右值 右值引用只能绑定右值 为什么需要完美转发？ 右值语义的引出 void set(const string &amp; var1, const string &amp; var2){ m_var1 = var1; //copy m_var2 = var2; //copy } A a1; string var1(&quot;string1&quot;); string var2(&quot;string2&quot;); a1.set(var1, var2); // OK to copy a1.set(&quot;temporary str1&quot;,&quot;temporary str2&quot;); //也需要copy，浪费 # 引入右值语义 void set(string &amp;&amp; var1, string &amp;&amp; var2){ //avoid unnecessary copy! m_var1 = std::move(var1); m_var2 = std::move(var2); } A a1; //temporary, move! no copy! a1.set(&quot;temporary str1&quot;,&quot;temporary str2&quot;); #但是要重载两遍，代码重复，所以引入完美转发 template&lt;typename T1, typename T2&gt; void set(T1 &amp;&amp; var1, T2 &amp;&amp; var2){ m_var1 = std::forward&lt;T1&gt;(var1); m_var2 = std::forward&lt;T2&gt;(var2); } /* forward 能够转发 [const] T &amp;[T] 的所有情况 const T &amp; T &amp; const T &amp;&amp; T &amp;&amp; when var1 is an rvalue, std::forward&lt;T1&gt; equals to static_cast&lt;[const] T1 &amp;&amp;&gt;(var1) when var1 is an lvalue, std::forward&lt;T1&gt; equals to static_cast&lt;[const] T1 &amp;&gt;(var1) 如果外面传来了rvalue临时变量, 它就转发rvalue并且启用move语义. 如果外面传来了lvalue, 它就转发lvalue并且启用复制. 然后它也还能保留const. */ 右值引用 auto for loop 当你想要拷贝range的元素时，使用for(auto x : range). 当你想要修改range的元素时，使用for(auto &amp;&amp; x : range). 当你想要只读range的元素时，使用for(const auto &amp; x : range). 其他的auto变种，几乎没有作用。 T&amp;&amp; Doesn’t Always Mean “Rvalue Reference” by Scott Meyers https://isocpp.org/blog/2012/11/universal-references-in-c11-scott-meyers Widget&amp;&amp; var1 = someWidget; // here, “&amp;&amp;” means rvalue reference auto&amp;&amp; var2 = var1; // here, “&amp;&amp;” does not mean rvalue reference template&lt;typename T&gt; void f(std::vector&lt;T&gt;&amp;&amp; param); // here, “&amp;&amp;” means rvalue reference template&lt;typename T&gt; void f(T&amp;&amp; param); // here, “&amp;&amp;”does not mean rvalue reference &amp;&amp; is not only type declaration, you will misread a lot of c++11 code. The essence of the issue is that “&amp;&amp;” in a type declaration sometimes means rvalue reference, but sometimes it means either rvalue reference or lvalue reference. 只有在类型推断（模板和auto）的时候，&amp;&amp;是universe reference，要看传入的值是rvalue还是lvalue： Universal references can only occur in the form “T&amp;&amp;”! 例如 template &lt;typename T&gt; void f(T&amp;&amp; param); f(10) // rvalue int x = 10; f(x) // lvalue template &lt;typename T&gt; void f(const T&amp;&amp; param) //rvalue, not universe reference. universe reference只认 T&amp;&amp; 形式 //error 不能把rvalue绑定到non-const lvalue reference // 如果把f参数改为const int&amp; a 那就没办法对a进行改变，也有限制 #include &lt;iostream&gt; using namespace std; int f(int&amp; a){ cout &lt;&lt; a &lt;&lt; endl; } int main() { cout &lt;&lt; f(3); return 0; } /* main.cpp:9:14: error: cannot bind non-const lvalue reference of type ‘int&amp;’ to an rvalue of type ‘int’ 9 | cout &lt;&lt; f(3); */ //一个很好的例子，来说明右值为什么有必要存在 //given the expression E(a, b, ... , c), we want the expression f(a, b, ... , c) to be equivalent. //不能处理f(1,2,3) template &lt;typename A, typename B, typename C&gt; void f(A&amp; a, B&amp; b, C&amp; c) { E(a, b, c); } # 如果E中要对a b c进行修改，则void E(int&amp;, int&amp;, int&amp;); f(i, j, k); // oops! E cannot modify these template &lt;typename A, typename B, typename C&gt; void f(const A&amp; a, const B&amp; b, const C&amp; c) { E(a, b, c); } #使用const_cast，但是E修改了const object，与f的函数签名不一致了 template &lt;typename A, typename B, typename C&gt; void f(const A&amp; a, const B&amp; b, const C&amp; c) { E(const_cast&lt;A&amp;&gt;(a), const_cast&lt;B&amp;&gt;(b), const_cast&lt;C&amp;&gt;(c)); } #重载跨域解决这个问题 但是2^N的重载个数，太麻烦 template &lt;typename A, typename B, typename C&gt; void f(A&amp; a, B&amp; b, C&amp; c); template &lt;typename A, typename B, typename C&gt; void f(const A&amp; a, B&amp; b, C&amp; c); template &lt;typename A, typename B, typename C&gt; void f(A&amp; a, const B&amp; b, C&amp; c); template &lt;typename A, typename B, typename C&gt; void f(A&amp; a, B&amp; b, const C&amp; c); template &lt;typename A, typename B, typename C&gt; void f(const A&amp; a, const B&amp; b, C&amp; c); template &lt;typename A, typename B, typename C&gt; void f(const A&amp; a, B&amp; b, const C&amp; c); template &lt;typename A, typename B, typename C&gt; void f(A&amp; a, const B&amp; b, const C&amp; c); template &lt;typename A, typename B, typename C&gt; void f(const A&amp; a, const B&amp; b, const C&amp; c); universe reference 推导规则 g1. 形如&quot;T&amp;&amp;&quot;的表达式（必须严格类似这个形式，不可有任何c-v限定符）且T是一个需要推导的东西，那么该表达式的类型可以称为universal reference。 g2. universal reference最终既可以最后推导为左值引用，也可以推导为右值引用。 ==&gt;d1. 推论1. 形如&quot;T&amp;&amp;&quot;的表达式，不一定都是右值引用。 g3. 某个变量的类型可以是右值引用，但包含该变量本身可以是左值。（只要能被取址的，就是左值） 特别的，Named variables and parameters of rvalue reference type are lvalues. (You can take their addresses.) [1] Keep in mind, once inside the function the parameter could be passed as an lvalue to anything. [2] G4-5 T应该如何被推导？ g4. 当形如&quot;T&amp;&amp;&quot;的universal reference被lvalue初始化时, T被推导为lvalue reference。 g5. 当形如&quot;T&amp;&amp;&quot;的universal reference被rvalue初始化时, T被推导为该rvalue的原生类型。 g6. 当形如&quot;T&amp;&amp;&quot;的universal reference所在模板函数传入的参数为引用类型（无论左值引用还是右值引用）时，实参的引用部分被忽略。 并由于传入的东西是左值（类型是引用，变量本身都为左值），T按g4规则被推导为lvalue reference。 G7-8 universal reference的整体类型最终如何确定？ g7. 当universal reference被lvalue初始化时，universal reference最终是左值引用. g8. 当universal reference被rvalue初始化时，universal reference最终是右值引用. g9. 重载与左值引用： 若存在一个函数的重载，其参数是左值引用或右值引用，当传入的参数为左值时，匹配左值引用的重载函数；当传入的参数为右值时，匹配右值引用的重载函数。如果有原生类型的重载函数，则语法会报错“多个重载函数匹配同一个调用”。 例子 template &lt;typename T&gt; void f(T&amp;&amp; para) { // do something; } int x; int &amp;&amp;a = 10; //a的类型是int&amp;&amp;，右值引用 int &amp;b = x; //b的类型是int&amp;，左值引用 f(10); // 10是右值，para的类型是右值引用，T是10的原生类型也就是int 函数f会实例化为 f(int&amp;&amp; para) f(x); // x是左值，para的类型是左值引用，T是左值引用，函数f会实例化为 f(int&amp; &amp;&amp; para) f(a); // g6./g4. a是右值引用，本身是左值，T是左值引用，函数f会实例化为 f(int&amp; &amp;&amp; para) f(b); // g6./g4. b是左值引用，本身是左值，T是左值引用，函数f会实例化为 f(int&amp; &amp;&amp; para) a是引用，且是一个lvalue a是lvalue --&gt; 所以T是int&amp;， a是引用，要引用去掉，只保留本体 所以universe reference T&amp;&amp; param：判断T是通过传入的实参是lvalue还是rvalue；如果实参是引用就把引用符号都去掉，且一定是lvalue。 右值引用 int main() { lambda_capture_value(); int a; int &amp;b = a; // int &amp;&amp;c = a; //error: rvalue reference to type 'int' cannot bind to lvalue of type 'int' } 为什么不允许non-const reference绑定到non-lvaule，因为存在逻辑错误： void increase(int &amp;v){ v++; } void foo(){ double s = 1.3; increase(s); //报错了：int&amp; 不能引用double类型的参数，所以必须产生一个临时值来保存s的值，从而当increase修改临时值时，s并没有被改变 } 为什么允许常量引用绑定到非左值，很简单，因为Fortan需要。 T&amp;&amp; + 传入的是右值，模板参数T才会被推导为右引用类型，例如T = int&amp;&amp; 为什么在循环语句中，auto&amp;&amp; 是最安全的方式：因为当auto被推导为不同的左右引用时，与&amp;&amp;的坍塌组合是完美转发（参考forward） template&lt;typename _Tp&gt; constexpr _Tp &amp;&amp;forward(typename std::remove_reference&lt;_Tp&gt;::type &amp;__t) noexcept { return static_cast&lt;_Tp &amp;&amp;&gt;(__t); } template&lt;typename _Tp&gt; constexpr _Tp &amp;&amp;forward(typename std::remove_reference&lt;_Tp&gt;::type &amp;&amp;__t) noexcept { static_assert(!std::is_lvalue_reference&lt;_Tp&gt;::value, &quot;template argument&quot; &quot; substituting _Tp is an lvalue reference type&quot;); return static_cast&lt;_Tp &amp;&amp;&gt;(__t); } 在这份实现中，std::remove_reference 的功能是消除类型中的引用，而 std::is_lvalue_reference 用于检查类型推导是否正确，在 std::forward 的第二个实现中检查了接收到的值确实是一个左值，进 而体现了坍缩规则。 当 std::forward 接受左值时，_Tp 被推导为左值，而所以返回值为左值；而当其接受右值时，_Tp 被推导为右值引用，则基于坍缩规则，返回值便成为了 &amp;&amp; + &amp;&amp; 的右值。可见 std::forward 的原理在 于巧妙的利用了模板类型推导中产生的差异。 ","link":"https://yangyueren.github.io/post/c-you-zhi-yin-yong/"},{"title":"MIT Missing Semester in CS Education : Shell Notes","content":"shell and useful tools 找shell命令的历史记录 ctrl-r 快捷键 字符串： '' ：原义字符串 “” ：转义 foo=bar echo '$foo' # $foo echo &quot;$foo&quot; # bar 练习：假设您有一个命令，它很少出错。因此为了在出错时能够对其进行调试，需要花费大量的时间重现错误并捕获输出。 编写一段bash脚本，运行如下的脚本直到它出错，将它的标准输出和标准错误流记录到文件，并在最后输出所有内容。 加分项：报告脚本在失败前共运行了多少次。 #!/usr/bin/env bash n=$(( RANDOM % 100 )) if [[ n -eq 42 ]]; then echo &quot;Something went wrong&quot; &gt;&amp;2 echo &quot;The error was using magic numbers&quot; exit 1 fi echo &quot;Everything went according to plan&quot; solution # !/bin/bash #$0 - 脚本名 #$1 到 $9 - 脚本的参数。 $1 是第一个参数，依此类推。 #$@ - 所有参数 #$# - 参数个数 #$? - 前一个命令的返回值; 0 代表正常返回，其他非0返回表示有错误发生 #$$ - 当前脚本的进程识别码 #!! - 完整的上一条命令，包括参数。常见应用：当你因为权限不足执行命令失败时，可以使用 su do !!再尝试一次。 file=&quot;failure.sh&quot; ./$file 1&gt;&gt;run.log 2&gt;&gt;error.log # 1代表stdout 重定向到run.log while [[ $? -eq 0 ]]; do ./$file 1&gt;&gt;run.log 2&gt;&gt;error.log done echo &quot;$0 finished&quot; sshfd可以将远端服务器的一个文件夹挂载到本地，然后使用本地的编辑器了。 练习： 如果您希望某个进程结束后再开始另外一个进程， 应该如何实现呢？在这个练习中，我们使用 sleep 60 &amp; 作为先执行的程序。一种方法是使用 wait 命令。尝试启动这个休眠命令，然后待其结束后再执行 ls 命令。 但是，如果我们在不同的 bash 会话中进行操作，则上述方法就不起作用了。因为 wait 只能对子进程起作用。之前我们没有提过的一个特性是，kill 命令成功退出时其状态码为 0 ，其他状态则是非0。kill -0 则不会发送信号，但是会在进程不存在时返回一个不为0的状态码。请编写一个 bash 函数 pidwait ，它接受一个 pid 作为输入参数，然后一直等待直到该进程结束。您需要使用 sleep 来避免浪费 CPU 性能。 #!/bin/bash com=&quot;kill -0 $1&quot; echo $com $com while [[ $? -eq 0 ]]; do echo &quot;$1 is still running&quot; sleep 60 done echo &quot;$1 doesn't exist&quot; ","link":"https://yangyueren.github.io/post/mit-missing-semester-in-cs-education-shell-notes/"},{"title":"前端 Vue-cli4.x项目执行顺序","content":"由于要做一个可视化，选择了vue，但是在使用过程中不清楚vue的启动过程导致写出的代码不够满意，于是在此理顺vue的启动过程。 代码如下： src --components |----HelloWorld.vue --router |----index.js --views |--Home.vue --App.vue main.js index.html 启动过程：main.js --&gt; App.vue --&gt; router/index.js --&gt; Home.vue --&gt; HelloWorld.vue index.html是初始文件，vue会替换掉id=app的dom index.html &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1.0&quot;&gt; &lt;title&gt;detection_web_vue&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;app&quot;&gt;&lt;/div&gt; &lt;!-- built files will be auto injected --&gt; &lt;/body&gt; &lt;/html&gt; main.js是首先执行的文件，是入口函数，创建一个Vue，把App component绑定到#app的dom main.js // The Vue build version to load with the `import` command // (runtime-only or standalone) has been set in webpack.base.conf with an alias. import Vue from 'vue' import App from './App' import router from './router' Vue.config.productionTip = false /* eslint-disable no-new */ new Vue({ el: '#app', router, components: { App }, template: '&lt;App/&gt;' }) 这里的router-link会被渲染 router-view也会被渲染，进入router/index.js中 App.vue &lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;img src=&quot;./assets/logo.png&quot;&gt; &lt;router-link to='/home'&gt; Home &lt;/router-link&gt; &lt;router-view/&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: 'App' } &lt;/script&gt; &lt;style&gt; #app { font-family: 'Avenir', Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; margin-top: 60px; } &lt;/style&gt; 引入了HelloWorld组件，在Home中使用 router/index.js import Vue from 'vue' import Router from 'vue-router' import HelloWorld from '@/components/HelloWorld' import Home from '@/views/Home' Vue.use(Router) export default new Router({ routes: [ { path: '/home', name: 'Home', component: Home } ] }) Home.vue &lt;template&gt; &lt;div class=&quot;hello&quot;&gt; &lt;h2&gt;Essential Links&lt;/h2&gt; &lt;HelloWorld/&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import HelloWorld from '@/components/HelloWorld.vue' export default { name: 'Home', components: { HelloWorld } } &lt;/script&gt; &lt;!-- Add &quot;scoped&quot; attribute to limit CSS to this component only --&gt; &lt;style scoped&gt; h1, h2 { font-weight: normal; } ul { list-style-type: none; padding: 0; } li { display: inline-block; margin: 0 10px; } a { color: #42b983; } &lt;/style&gt; HelloWorld.vue &lt;template&gt; &lt;div class=&quot;hello&quot;&gt; &lt;h1&gt;{{ msg }}&lt;/h1&gt; &lt;h2&gt;Essential Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href=&quot;https://vuejs.org&quot; target=&quot;_blank&quot; &gt; Core Docs &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https://forum.vuejs.org&quot; target=&quot;_blank&quot; &gt; Forum &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https://chat.vuejs.org&quot; target=&quot;_blank&quot; &gt; Community Chat &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https://twitter.com/vuejs&quot; target=&quot;_blank&quot; &gt; Twitter &lt;/a&gt; &lt;/li&gt; &lt;br&gt; &lt;li&gt; &lt;a href=&quot;http://vuejs-templates.github.io/webpack/&quot; target=&quot;_blank&quot; &gt; Docs for This Template &lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Ecosystem&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href=&quot;http://router.vuejs.org/&quot; target=&quot;_blank&quot; &gt; vue-router &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;http://vuex.vuejs.org/&quot; target=&quot;_blank&quot; &gt; vuex &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;http://vue-loader.vuejs.org/&quot; target=&quot;_blank&quot; &gt; vue-loader &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https://github.com/vuejs/awesome-vue&quot; target=&quot;_blank&quot; &gt; awesome-vue &lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: 'HelloWorld', data () { return { msg: 'Welcome to Your Vue.js App' } } } &lt;/script&gt; &lt;!-- Add &quot;scoped&quot; attribute to limit CSS to this component only --&gt; &lt;style scoped&gt; h1, h2 { font-weight: normal; } ul { list-style-type: none; padding: 0; } li { display: inline-block; margin: 0 10px; } a { color: #42b983; } &lt;/style&gt; ","link":"https://yangyueren.github.io/post/qian-duan-vue-cli4x-xiang-mu-zhi-xing-shun-xu/"},{"title":"CSAPP RIO包用于I/O","content":" RIO - 解决short count - 提供方便、健壮、高效的IO 两类函数 - 无缓冲的输入输出 rio_readn rio_writen ​ 绝不会返回不足值 - 带缓冲的输入输出 ​ rio_readlineb ​ 读文本行 ​ 停止条件 ​ 读了maxlen个字节 ​ 遇到了EOF ​ 遇到了换行符 ​ rio_readnb ​ 读字节 不区分文本和二进制文件 ​ 停止条件 ​ maxlen : 因为里面用了一个while循环，如果还有left，就继续读，如果buffer已经空了，就调用rio_read填充buffer后再读。 ​ 遇到EOF ​ ​ readlineb和readnb可以混用，但不能和readn混用 /*my version of rio*/ #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;fcntl.h&gt; #include &lt;string.h&gt; #include &lt;errno.h&gt; typedef struct{ int rio_fd; //file descriptor int rio_cnt; //unread bytes char rio_buffer[32]; char *rio_p; //pointer to next unread byte; } rio_t; void rio_initb(rio_t *rp, int fd){ rp-&gt;rio_fd = fd; rp-&gt;rio_cnt = 0; rp-&gt;rio_p = rp-&gt;rio_buffer; } //把buffer里的拷贝进usrbuf int rio_read(rio_t *rp, char *usrbuf, size_t size){ while(rp-&gt;rio_cnt &lt;= 0){ rp-&gt;rio_cnt = read(rp-&gt;rio_fd, rp-&gt;rio_buffer, sizeof(rp-&gt;rio_buffer)); if(rp-&gt;rio_cnt &lt; 0){ if(errno != EINTR){ return -1; } }else if(rp-&gt;rio_cnt == 0){ return 0; }else{ rp-&gt;rio_p = rp-&gt;rio_buffer; } } int cnt = size; if(cnt &gt; rp-&gt;rio_cnt){ cnt = rp-&gt;rio_cnt; } memcpy(usrbuf, rp-&gt;rio_p, cnt); rp-&gt;rio_p += cnt; rp-&gt;rio_cnt -= cnt; return cnt; } int rio_readnb(rio_t *rp, char *des, size_t size){ int left = size; int n; char *p = des; while(left &gt; 0){ n = rio_read(rp, p, left); if(n &lt; 0){ return -1; /* errno set by read() */ }else if(n==0){ break; /* EOF */ }else{ left -= n; p += n; } } return (size - left); } int rio_readlineb(rio_t *rp, char* des, size_t max_size){ int left = max_size-1; char *p = des; int n; while(left &gt; 0){ if(n = rio_read(rp, p, 1) == 1){ left--; if(*p == '\\n'){ p++; break; }else{ p++; } }else if(n==0){ if(p == des) return 0; //no data read, EOF else break; // some data read, EOF }else{ return -1; } } *p = 0; return p-des; } int main() { rio_t rt; int fd1 = open(&quot;README2&quot;, O_RDONLY); rio_initb(&amp;rt, fd1); char buf[64]; int size = 64; rio_readlineb(&amp;rt, buf, size); printf(&quot;%s&quot;, buf); } /**************************************** * The Rio package - Robust I/O functions ****************************************/ /* * rio_readn - Robustly read n bytes (unbuffered) */ /* $begin rio_readn */ ssize_t rio_readn(int fd, void *usrbuf, size_t n) { size_t nleft = n; ssize_t nread; char *bufp = usrbuf; while (nleft &gt; 0) { if ((nread = read(fd, bufp, nleft)) &lt; 0) { if (errno == EINTR) /* Interrupted by sig handler return */ nread = 0; /* and call read() again */ else return -1; /* errno set by read() */ } else if (nread == 0) break; /* EOF */ nleft -= nread; bufp += nread; } return (n - nleft); /* Return &gt;= 0 */ } /* $end rio_readn */ /* * rio_writen - Robustly write n bytes (unbuffered) */ /* $begin rio_writen */ ssize_t rio_writen(int fd, void *usrbuf, size_t n) { size_t nleft = n; ssize_t nwritten; char *bufp = usrbuf; while (nleft &gt; 0) { if ((nwritten = write(fd, bufp, nleft)) &lt;= 0) { if (errno == EINTR) /* Interrupted by sig handler return */ nwritten = 0; /* and call write() again */ else return -1; /* errno set by write() */ } nleft -= nwritten; bufp += nwritten; } return n; } /* $end rio_writen */ /* * rio_read - This is a wrapper for the Unix read() function that * transfers min(n, rio_cnt) bytes from an internal buffer to a user * buffer, where n is the number of bytes requested by the user and * rio_cnt is the number of unread bytes in the internal buffer. On * entry, rio_read() refills the internal buffer via a call to * read() if the internal buffer is empty. */ /* $begin rio_read */ static ssize_t rio_read(rio_t *rp, char *usrbuf, size_t n) { int cnt; while (rp-&gt;rio_cnt &lt;= 0) { /* Refill if buf is empty */ rp-&gt;rio_cnt = read(rp-&gt;rio_fd, rp-&gt;rio_buf, sizeof(rp-&gt;rio_buf)); if (rp-&gt;rio_cnt &lt; 0) { if (errno != EINTR) /* Interrupted by sig handler return */ return -1; } else if (rp-&gt;rio_cnt == 0) /* EOF */ return 0; else rp-&gt;rio_bufptr = rp-&gt;rio_buf; /* Reset buffer ptr */ } /* Copy min(n, rp-&gt;rio_cnt) bytes from internal buf to user buf */ cnt = n; if (rp-&gt;rio_cnt &lt; n) cnt = rp-&gt;rio_cnt; memcpy(usrbuf, rp-&gt;rio_bufptr, cnt); rp-&gt;rio_bufptr += cnt; rp-&gt;rio_cnt -= cnt; return cnt; } /* $end rio_read */ /* * rio_readinitb - Associate a descriptor with a read buffer and reset buffer */ /* $begin rio_readinitb */ void rio_readinitb(rio_t *rp, int fd) { rp-&gt;rio_fd = fd; rp-&gt;rio_cnt = 0; rp-&gt;rio_bufptr = rp-&gt;rio_buf; } /* $end rio_readinitb */ /* * rio_readnb - Robustly read n bytes (buffered) */ /* $begin rio_readnb */ ssize_t rio_readnb(rio_t *rp, void *usrbuf, size_t n) { size_t nleft = n; ssize_t nread; char *bufp = usrbuf; while (nleft &gt; 0) { if ((nread = rio_read(rp, bufp, nleft)) &lt; 0) return -1; /* errno set by read() */ else if (nread == 0) break; /* EOF */ nleft -= nread; bufp += nread; } return (n - nleft); /* return &gt;= 0 */ } /* $end rio_readnb */ /* * rio_readlineb - Robustly read a text line (buffered) */ /* $begin rio_readlineb */ ssize_t rio_readlineb(rio_t *rp, void *usrbuf, size_t maxlen) { int n, rc; char c, *bufp = usrbuf; for (n = 1; n &lt; maxlen; n++) { if ((rc = rio_read(rp, &amp;c, 1)) == 1) { *bufp++ = c; if (c == '\\n') { n++; break; } } else if (rc == 0) { if (n == 1) return 0; /* EOF, no data read */ else break; /* EOF, some data was read */ } else return -1; /* Error */ } *bufp = 0; return n - 1; } /* $end rio_readlineb */ ","link":"https://yangyueren.github.io/post/csapp-rio-bao-yong-yu-io/"},{"title":"ES使用过程中遇到的坑","content":"这是大三暑假完成的一个基于Elasticsearch的搜索引擎的心得篇，十五天的时间遇到了太多的坑，在此做记录。 深度搜索引擎体会 从7月5号到7月19号，历时十五天的课程结束了，深深的松了一口气，可以缓解一下身心的压力。 这次的项目，是这三年中做的最认真的一次，从5号到18号，每天晚上两点多睡，八点多起床吃早饭来机房，这门课让我半年来不早起不吃早饭的人，养成了吃早饭的习惯，每天来机房时手机的电量有90%，晚上回去的时候还能够剩下65%，每天的上班的六个小时，不熬夜是不可能的，每天晚上都在熬夜补充新的功能，一点点从0到1搭建起自己的系统，用了6台服务器，部署了ES的集群，成果颇丰。 以上是一些偏离主题的碎碎念，以下是正文。 我们此次项目做的是深度搜索引擎，爬取了小鸡词典、微博、b站等方面的数据，将数据清洗后存到Elasticsearch中，为了充分发挥ES的优势，我使用了三台服务器用来跑ES，一台服务器跑后端程序，另外还有两台图片搜索引擎的服务器，由队友负责搭建。 这个项目的简介可以在此github仓库中找到，在此不做赘述，本文着重讲述遇到的问题。 首先是Elasticsearch版本的问题，7.2的版本对java Springboot的支持太不友好了，maven里面找不到对7.2版本的ES的repository的插件，所以浪费了一天的时间在这个上面，期间我更换过到2.x的版本和5.x的版本，发现都不如人意，感谢其他组同学的支持，提供了解决思路，使用6.4的版本，最终解决问题。 在ES部署过程中，我一开始就是部署成了集群的状态，对于后续的开发不利，因为我有一台阿里云服务器一直崩溃，所以集群也一直崩溃，而那台服务器又是主节点，在被折磨两天后毅然选择关掉那台服务器，找同学借了其他的服务器。这也拖累了后面的开发进度。如果我一开始就是先在单节点上部署，可以先进行后续的开发，等到最后再来调整服务器集群的问题，这样我在项目的个性化搜索推荐方面还可以做的更加出色。 另一个坑是Springboot对ES的操作，Springboot在定义ES的索引的时候，没办法指定分词器，这就很尴尬。ES的默认分词器是英文的，对于中文的支持特特不友好。我输入的句子，他会拆分成一个个的字建立索引，这样的倒排索引，查一个句子的查询结果与预期的相关度相去甚远，归根结底是Spring自己建立索引时候我不会指定分词器，我最终选择学习ES的语法，首先配置好ES的index，只让Spring插入数据，不让他建索引，这样就解决了这个问题。 另外就是在java中对ES进行数据的查询，repository有些鸡肋，很多想进行的查询都没办法用。我后来查到了一种方法，是加@Query注解，一定程度上缓解了这个问题。其次是sort的问题，我们想做多维的排序，但是ES对这个支持的不是很好，比如有300条数据hit，但是我加入了sort的排序方式，相关度很低的结果可能被拍到前面。于是我在ES中查询时候没有使用sort，但是限制了page size，50左右，然后对返回的一个page的内容进行手动排序，于是手写了多维排序的方法。 为了java中的多维排序，我使用了最愚蠢的方法。我需要对time view like三个维度做多维排序，他们的排列组合有12种（3+6+6），于是我手写了12条下面的语句。 /*按照view like time排序*/ Collections.sort(modifyData, (a, b) -&gt; { if (!a.getView().equals(b.getView())) { return b.getView() - a.getView(); } else { if (!a.getLike().equals(b.getLike())) { return b.getLike() - a.getLike(); } else { if (!a.getTime().equals(b.getTime())) { return compareTime(b.getTime(),a.getTime()); } } } return 0; }); /*按照like time view排序*/ Collections.sort(modifyData, (a, b) -&gt; { if (!a.getLike().equals(b.getLike())) { return b.getLike() - a.getLike(); } else { if (!a.getTime().equals(b.getTime())) { return compareTime(b.getTime(),a.getTime()); } else { if (!a.getView().equals(b.getView())) { return b.getView() - a.getView(); } } } return 0; }); 这是一个比较愚蠢的方法吧，但是确实解决了我的问题，能够解决问题的办法就是好方法！当然了，我也在一直思考如何有更加优美的写法。 ","link":"https://yangyueren.github.io/post/2/"},{"title":"Chaggie Search Engine","content":"这是大三暑假完成的一个基于Elasticsearch的搜索引擎，后端及ES部分由我用Spring boot完成，前端和爬虫由队友完成。 基于Elasticsearch集群的数据查询优化 Elasticsearch是一个基于Lucene的分布式全文搜索引擎，能够横向扩展数以百计的服务器，存储PB级的数据，而且对每个字段都可以建立索引并且检索，并且可以在极短的时间内存储、搜索和分析大量的数据，程序员最爱的网站Github的搜索就是基于ES构建的，GitHub大约有30TB的索引文件数据，由此可见Elasticsearch（下文简称ES）强大的搜索功能。 在此次的深度搜索引擎项目之中，虽然Elasticsearch也可以在一个节点上使用，该节点可以同时担任master node和data node，但是为了发挥Elasticsearch的分布式搜索的优势，在我们的深度搜索引擎中我们使用了三台服务器提供Elasticsearch的服务。下文将详细介绍从集群部署到优化查询的一些要点。 一、Elasticsearch的集群部署 1. ES概念简介 Elasticsearch中有几个比较重要的概念，集群是指连接在一起的若干台服务器，不同的服务器承担不同的角色，一起提供服务。集群中有主节点、数据节点和客户端节点等。主节点负责管理整个集群，当群集的拓扑结构改变时把索引分片分派到相应的节点上，主节点是从可以担任主节点的节点中选举出来的。数据节点只负责存储数据，客户端节点在选举主节点过程中起作用。ES的分片是把索引信息分散到多个节点上，相当于一桶水用多个杯子装。副本是指索引信息的拷贝。 在进行ES的配置时，首先要考虑节点数和分片数。通过实验，多节点的ES集群中的节点数至少为3，分片数为一倍的节点数量到两倍的节点数量。 节点数和分片数相等时，每个节点负责一个分片的检索，ES集群的性能可以达到最优。对于一个3节点集群，为每个节点分配一个分片，总共3个分片。但是由于ES的不可变性的限制，系统无法对分片进行重新拆分分配，除非重新索引这个文件集合。但是我在三个节点的集群中再加入一个节点，这时候分片数量小于了节点数，在搜索上效率会降低，所以为了支持水平扩展，可以为集群分配比节点数更多的分片数，也就是说每个节点有多个分片。但是每个节点有多个分片时，需要考虑性能的问题，每个节点最好不要超过两个分片， 我采用了官方给默认配置中分片数目为5，这样既可以拓展到5个节点，也可以保证性能。 我的集群的其余配置如下图： #节点集群名称和节点类型 cluster.name: yang-es-clusters node.name: node-3 node.master: true node.data: true #同个集群其他节点的信息，ES通过广播的方式寻找同一集群的其他节点 discovery.zen.ping.unicast.hosts: [ &quot;0.0.0.0&quot;, &quot;106.14.191.xxx&quot;, &quot;120.79.191.xxx&quot;] #选举主节点时需要由至少2个节点参与投票 discovery.zen.minimum_master_nodes: 2 gateway.recover_after_nodes: 1 #配置本节点的ip，默认开发9300端口用于节点间TCP通信 network.host: 0.0.0.0 network.publish_host: 106.14.227.30 network.bind_host: 0.0.0.0 2. Elsaticsearch集群至少需要有三个节点 上文写到我们组搭建的ES集群使用了三台服务器，这也是搭建ES集群所需的最少节点数，是因为需要防止ES集群发生脑裂。ES中维护索引状态最重要的节点是主节点，主节点是被投票选举出来的。 三个和尚投票 当主节点出现问题，从节点不能与主节点通信时，从节点会发起选举任命新的主节点，同时新的主节点会接管旧的主节点的所有工作，如果旧的主节点重新恢复并加入到集群中，新的主节点会将原来旧的主节点降级为从节点，这样就不会有冲突发生。所有这个过程都由ES自己处理，使用者无需任何参与。 两个和尚投票 但是，当只有两个节点的时候，一主（master）一从（slave），如果主从直接的通信出现问题时，从节点slave会自我提升为master，但是当恢复通信时，我们就会同时有两个master。因为此时，对于原来的主节点角度考虑，它认为是原来的从节点出现问题，现在仍然需要作为slave重新加入。这样，两个节点的时候，我们就出现了集群不知道将哪个节点选举为主节点的情况，也就是我们通常说的“分脑”。 为了防止这种情况的发生，第三个节点的出现会打破平衡，解决冲突问题。 三个和尚仍然存在问题 分脑的问题同样会出现在具有三或三个以上节点的集群中，为了降低发生的概率，ElasticSearch提供了一个配置 discovery.zen.minimum_master_nodes它规定了在选举新的master时，一个集群下最少需要的节点数。例如，一个3节点集群，这个数字为2，2个节点可以防止单个节点在脱离集群时，将其自己选举成master，相反，它会等待直到重新加入到集群中。这个数值可以通过一个公式确定： 这里的配置是指当主节点宕掉掉时候至少同时需要几个节点才重新进行投票选举新的主节点，官方建议将此数目配置为N / 2 + 1，可以有效的防止脑裂。 discovery.zen.minimum_master_nodes: 2 从图中分析可以得知，如果只有两个节点，当这两个节点通讯故障的时候，会各自选举自己为主节点，而当通讯恢复正常时候会发生冲突，这与区块链的思想不谋而合，只有控制了51%以上的节点，才可以掌控整个集群。 我在配置ES的时候，主节点所在的服务器由于网络问题，经常会发生断网的现象，此时集群的状态会由绿色（正常）转变为红色（预警）状态，而当非主节点宕机的时候，集群状态会变为黄色（所有的主分片可用，但是副本分片不可用）。这个问题的解决方案只有一种，设置容易宕机的节点为数据节点，禁止其被选举为主节点。 二、Elasticsearch的查询参数优化 1. Lucene的打分模型 由于ES是基于Lucene，所以ES也是使用的打分机制。通过上面的公式，一篇文档的分数实际上是由查询语句q和文档d作为变量的一个函数值。打分公式中有两部分不直接依赖于查询词，它们是coord和queryNorm。公式的值是这样计算的，coord和queryNorm两大部分直接乘以查询语句中每个查询词计算值的总和。另一方面，这个总和也是由每个查询词的词频(tf)，逆文档频率(idf)，查询词的权重，还有norm，也就是前面说的length norm相乘而得的结果。 从中可以得出以下几条规则： 匹配到的关键词越稀有，文档的得分就越高。 文档的域越小(包含比较少的Term)，文档的得分就越高。 设置的权重(索引和搜索时设置的都可以)越大，文档得分越高。 随着Lucene的发展，打分模型也引入了新的相似度模型，并且可以在ES中指定，现在比较流行的是Okapi BM25，Divergence from randomness和Information based。 BM25是基于概率模型的相似度模型，适合处理短文本，关键词的重复次数对整个文档得分影响比较大。DFR和IB比较类似，基于同名概率模型，适用于自然语言类的文本。我们的搜索引擎要搜索的字段比较少，内容也是以短文本为主，并且倾向于能够对名字和标签进行准确匹配，如果关键词在内容中多次重复，明显词条是用户所查询的结果，所以BM25更加适合我们的搜索引擎。 2. 分词器的选择 ES是基于词的搜索引擎，其能够快速的通过搜索词检索出对应的文章归功于倒排索引，使用不同的分词器对于检索效果也有重大影响。 ES的默认分词器对英文句子的切割效果比较好，但用于中文句子的分割时，只会将句子分割成孤立的一个个的字，所以需要指定建立索引时的分词器和搜索分词器。我们使用的是IKAnalyzer，是目前比较流行的中文分词器之一,设置比较简单,稳定。 在Sprint Boot中建立索引时候，对ES的支持度不如直接在ES里面自己建立索引可操作性高，以下是我建立索引的代码。 curl -XPOST http://106.14.227.30:9200/chageng/EntryDb/_mapping -H 'Content-Type:application/json' -d' { &quot;EntryDb&quot;: { &quot;properties&quot;: { &quot;content&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; } } }, &quot;imageList&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;like&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; } } } }' 3. 查询语句的优化 3.1 term、match与multi_match ES中的term是代表完全匹配，也就是精确查询，搜索前不会再对搜索词进行分词，所以我们的搜索词必须是文档分词集合中的一个。以下代码将会在name中精确匹配为“小鸡快跑”的词条。 curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d ' { &quot;query&quot;:{ &quot;term&quot;:{ &quot;name&quot;:&quot;小鸡快跑&quot; } } }' ES的match搜索会先对搜索词进行分词，对于最基本的match搜索来说，只要搜索词的分词集合中的一个或多个存在于文档中即可，例如，当我们搜索小鸡快跑，搜索词会先分词为小鸡和快跑,只要文档中包含小鸡和快跑任意一个词，都会被搜索到。 如果文档1中有小鸡，文档2中有快跑，那么这两个文档都会被检索到，而如果文档3中有小鸡和快跑两个词，文档3也将被返回，并且文档3将被排在首位。所有被返回的文档将依靠_score的分数进行排序，得分的算法参考上文。 curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d ' { &quot;query&quot;: { &quot;match&quot;: { &quot;content&quot;: &quot;小鸡快跑&quot; } } }' ES的multi_match是对多个字段进行匹配，其中一个字段包含分词，该文档即可被搜索到并且返回。在实际使用中用的比较多。 curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d ' { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: { &quot;tagList&quot;: &quot;社交&quot; } }, &quot;should&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;吓得我瓜子都掉了&quot;, &quot;type&quot;: &quot;best_fields&quot;, &quot;fields&quot;: [ &quot;name^2&quot;, &quot;content&quot; ], &quot;fuzziness&quot;: &quot;AUTO&quot;, &quot;tie_breaker&quot;: 0.4, &quot;minimum_should_match&quot;: &quot;30%&quot; } } } } } ' 3.2 组合过滤器bool bool 过滤器通过 and 、 or 和 not 逻辑组合将多个过滤器进行组合。bool 查询可以接受 must 、 must_not 和 should 参数下的多个查询语句，对查询结果进行筛选，分别对应AND NOT OR。bool 查询会为每个文档计算相关度评分 _score ， 再将所有匹配的 must 和 should 语句的分数 _score 求和，最后除以 must 和 should 语句的总数。 must_not 语句不会影响评分； 它的作用只是将不相关的文档排除。 should过滤的数量是由minimum_should_match参数来进行控制，该参数可以是百分比，也可以是一个数字，我在多次实验后发现40%的效果最好。 以下是bool的基本用法。 curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d ' { &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot;: { &quot;tagList&quot;: &quot;游戏&quot; } }, &quot;should&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;秦王&quot;, &quot;type&quot;: &quot;best_fields&quot;, &quot;fields&quot;: [ &quot;name^5&quot;, &quot;tagList^2&quot;, &quot;content^1&quot; ], &quot;tie_breaker&quot;: 0.4, &quot;minimum_should_match&quot;: &quot;40%&quot; } }, &quot;filter&quot;: { &quot;range&quot;: { &quot;time&quot;: { &quot;gte&quot;: &quot;2012-09-09&quot;, &quot;lt&quot;: &quot;2019-09-09&quot; } } } } } }' 3.3 boost权重控制 在多字段匹配中，我在name tagList 和 content字段中对内容进行查询，但是想让name字段拥有有更高的权重，可以通过指定 boost 来控制任何查询语句的相对的权重， boost 的默认值为 1 ，大于 1 会提升一个语句的相对权重。基本使用见上条ES语句。 基于 TF/IDF 的评分模型中，如果使用了boost改变权重，新的评分 _score 会在应用权重提升之后进行归一化处理 ，并不是线性的变化。 3.4 模糊匹配 模糊查询的工作原理是给定原始词项及构造一个编辑自动机— 像表示所有原始字符串指定编辑距离的字符串的一个大图表。然后模糊查询使用这个自动机依次高效遍历词典中的所有词项以确定是否匹配。 一旦收集了词典中存在的所有匹配项，就可以计算匹配文档列表。在搜索巨大文档时候，模糊匹配的效率很低，故可以用以下两个参数限制对性能的影响，prefix_length为不能被 “模糊化” 的初始字符数，建议设置为了3，max_expansions限制产生的模糊选项的总数量。 curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d ' { &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;吓得我瓜子都掉了&quot;, &quot;type&quot;: &quot;best_fields&quot;, &quot;fields&quot;: [ &quot;name^2&quot;, &quot;content&quot; ], &quot;fuzziness&quot;: &quot;AUTO&quot;, &quot;tie_breaker&quot;: 0.4, &quot;minimum_should_match&quot;: &quot;40%&quot; } } }' 3.5 随机评分 我们的搜索词条结果集中有很多点赞数一样的词条，在指定按点赞数排序这种方式后，有相同评分 _score 的文档会每次都以相同次序出现，为了提高展现率，可以引入一些随机性，保证有相同评分的文档都能有均等相似的展现机率。 每个用户看到不同的随机次序，但也同时希望如果是同一用户翻页浏览时，结果的相对次序能始终保持一致。这种行为被称为 一致随机（consistently random） 。 引用：https://www.elastic.co/guide/cn/elasticsearch/guide/current/random-scoring.html 以下是样例： curl -XPOST '106.14.227.30: 9200/chageng/_search?pretty' -H 'Content-Type: application/json' -d ' { &quot;query&quot;: { &quot;function_score&quot;: { &quot;filter&quot;: { &quot;match&quot;: { &quot;name&quot;: &quot;小鸡快跑&quot; } }, &quot;functions&quot;: [ { &quot;filter&quot;: { &quot;term&quot;: { &quot;tagList&quot;: &quot;小鸡&quot; }}, &quot;weight&quot;: 1 }, { &quot;filter&quot;: { &quot;term&quot;: { &quot;tagList&quot;: &quot;游戏&quot; }}, &quot;weight&quot;: 2 }, { &quot;random_score&quot;: { &quot;seed&quot;: &quot;the users session id&quot; } } ], &quot;score_mode&quot;: &quot;sum&quot; } } } 三、Elasticsearch性能问题 1. 数据预热: ES可以在查询前进行预热，将查询中十分依赖的字段的数据加载出来，可以使用Elasticsearch为类型和索引定义预热查询。 定义一个新的预热查询，和普通查询没什么区别，只是它存储在Elasticsearch一个特殊的名为_warmer的索引中，以下是我的预热查询。 curl -XPUT '106.14.227.30: 9200/chageng/_warmer?pretty' -H 'Content-Type: application/json' -d ' { &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;facets&quot;: { &quot;warming_facet&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;name&quot; } } } }' 2. 优化索引 我建立的索引，每个词条都包含较多的内容，不仅包括了该词条的基本信息（name，tag，content，view，like），还包括了从微博、B站、谷歌等地方爬取到的相关信息，每个词条中包含的数据比较多，对完整的词条建立索引，每次的查询速度与在mongodb里面检索持平，在做自动补全时能够有肉眼可见的延迟。 出现查询速度过慢的情况有两方面的原因。第一是建立的索引包含的内容过多，比如微博、B站的数据大约是该词条的基本信息的25倍以上，而这些微博、B站的信息我们在做检索的时候并不需要对这些字段进行检索，这些无效的信息拖累了检索速度。第二是网络传输延迟，因为我们的ES集群和我们的搜索引擎服务并不在同一个机器上面，他们之间是通过网络进行通信，由于每条词条包含数据比较大，所以如果查询结果中有上百条的数据被命中，返回这些数据时需要比较多的时间。 我们的解决方案是建立两个索引，第一个索引存储词条的基本信息，第二个索引存储词条的所有信息，但使用检索功能的时候，我们只需要在第一个索引中检索，将词条的基本信息返回呈现给用户，这样可以大大加快速度。为了将速度优化到极致，在不影响用户正常使用的情况下，我们又对搜索结果的数量进行了限制，每次只返回当前页面要展现的搜索条目，最快的呈现给用户结果，其余的搜索结果用异步的方式加载。当用户进入词条详细页面时，我们可以通过该词条的id，到ES中的第二个索引中查找该id词条的所有信息进行返回，这样的检索速度能够提升到28倍。 3. 优化存储 上文提到索引可以存储到ES中，这样的查询效率最高，那具体的数据可以存储到MySQL、MongoDb，ES三种数据库中，考虑到我们的数据类型以json文件为主，MySQL需要建立多张表来实现关系间的映射，故不做考虑。 我对MongoDb存储词条的所有信息，与直接用ES存储所有的信息进行检索做了一个对比，发现两者在检索10000条数据运行时间上并没有太大差异，所以直接使用ES进行存储了所有的数据。 ","link":"https://yangyueren.github.io/post/1/"}]}